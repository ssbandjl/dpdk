源码分析-大页初始化: https://zzqcn.github.io/opensource/dpdk/code-analysis/mem.html
UIO原理和流程简析: https://blog.csdn.net/ApeLife/article/details/100751359

git remote add upstream https://github.com/DPDK/dpdk
git fetch upstream
git merge upstream/master



mlx5driver:
driver source code: https://blog.csdn.net/leiyanjie8995/article/details/121341828
struct rte_eth_dev { -> 与每个以太网设备关联的通用数据结构。 指向突发数据包接收和发送功能的指针位于该结构的开头，以及指向特定设备的所有数据元素存储在共享内存中的位置的指针。 这种分割允许每个进程使用函数指针和驱动程序数据，而设备的实际配置数据是共享的。

与框架相关的比较重要的，收发报文的接口是 rx_pkt_burst 和 tx_pkt_burst, 还有与网卡相关的初始化、配置等接口都在eth_dev_ops里。还有网卡设备的私有数据，带有硬件相关的各项参数和数据，记录在rte_eth_dev_data结构里，包括网卡名称、收发队列个数及列表、mac地址等等
值得注意的是，为了representor的概念，mellanox在rte_eth_dev_data结构里添加了一个名为representor_id的参数，用作representor设备的id
mellanox的驱动在drivers/common/mlx5和drivers/net/mlx5目录下。common目录下是通用pcie相关，包括pcie驱动、与硬件交互的接口封装；net目录下是更上层的接口，包括eth设备、representor相关的一系列操作






LPM, 最长掩码匹配, Longest Prefix matching: lib\lpm\rte_lpm.h
struct rte_lpm_tbl_entry

rte_lpm_create(const char *name, int socket_id, const struct rte_lpm_config *config)




rte_distributor_process -> 处理一组数据包并将其分发给worker




ptp presision timing protocol


查看大页: cat /proc/meminfo |grep -i huge

配置大页:
echo 16 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages
hugepage:
大页信息初始化
eal_hugepage_info_init(void) -> 当我们初始化大页信息时，默认情况下所有内容都会转到套接字 0。 稍后将按内存初始化过程排序. mem：共享主要和次要的大页信息，因为我们需要在主要和辅助进程中映射大页，所以我们需要知道应该在哪里寻找hugetlbfs挂载点。 因此，与辅助进程共享这些，并将它们映射到 init 上
    eal_get_internal_configuration
    hugepage_info_init
        const char dirent_start_text[] = "hugepages-";
        dir = opendir(sys_dir_path) -> static const char sys_dir_path[] = "/sys/kernel/mm/hugepages";
        for (dirent = readdir(dir); dirent != NULL; dirent = readdir(dir))
            rte_str_to_size(&dirent->d_name[dirent_start_len]) -> 大页目录名转整数
            get_hugepage_dir
            get_num_hugepages
            calc_num_pages
    create_shared_memory(eal_hugepage_info_path(),
    memcpy
    munmap

读取 /sys/kernel/mm/hugepages 中的“hugepages-XXX”目录，最多读取 3个。比如读取到 hugepages-2048kB ，将其中的 2048kB 转换为2048*1024，存入internal_config.hugepage_info[num_sizes].hugepage_sz， num_sizes<3
打开 /proc/meminfo 文件，读取 Hugepagesize 项的值，做为大页默认大小。打开 /proc/mounts 文件，找到类似 hugetlbfs /dev/hugepages hugetlbfs rw,seclabel,relatime 0 0 或 nodev /mnt/huge hugetlbfs rw,relatime 0 0 的行，根据选项(rw,relatime)中出现的 pagesize= 项的值(如果有的话)，来返回对应的大页文件系统挂载路径，如 /dev/hugepages 或 /mnt/huge ，将其存入internal_config.hugepage_info[num_sizes].hugedir
锁定hugedir(flock)
打开 sys/kernel/mm/hugepages/hugepages-XXX 目录下面的 resv_hugepages 和 free_hugepages 文件，计算可用大页数量， 存入internal_config.hugepange_info->num_pages[0]，这个0是socket id，在支持NUMA的系统中先在socket 0上进行操作
internal_config.num_hugepage_sizes数设置为num_sizes数，不大于3
将上述过程发现的所有num_sizes个大页信息按从大到小排序，并检查至少有一个可用大页尺寸

get and req hugepage: dpdk-hugepages.py --setup 2G


大页内存初始化
rte_eal_memory_init
    rte_eal_memseg_init
    eal_memalloc_init
    rte_eal_hugepage_init rte_eal_hugepage_attach
        map_all_hugepages
            eal_get_hugefile_path(hf->filepath, sizeof(hf->filepath), -> // 拼接文件名 /dev/hugepages/rte_hugepage_%s
            ...
            fd = open(hf->filepath, O_CREAT | O_RDWR, 0600);
            ...
            virtaddr = mmap(NULL, hugepage_sz, PROT_READ | PROT_WRITE,
                            MAP_SHARED | MAP_POPULATE, fd, 0);





uio:
dpdk-devbind.py



receive pkt:
rte_eth_rx_burst
    eth_igb_recv_pkts
        if (! (staterr & rte_cpu_to_le_32(E1000_RXD_STAT_DD))) -> check dma dd flag



send pkt:
rte_eth_tx_burst
    tx_queues -> rte_eth_tx_burst -> nb_pkts = p->tx_pkt_burst(qd, tx_pkts, nb_pkts)




how huge page init?


//主进程创建/var/run/.rte_config文件
mem_cfg_fd = open(pathname, O_RDWR | O_CREAT, 0660);
//主进程映射/var/run/.rte_config到主进程空间
rte_mem_cfg_addr = mmap(rte_mem_cfg_addr, sizeof(*rte_config.mem_config),PROT_READ | PROT_WRITE, MAP_SHARED, mem_cfg_fd, 0);

static void rte_config_init(void)
{
    switch (rte_config.process_type)
    {
        case RTE_PROC_PRIMARY:
             //主进程创建共享内存配置
            rte_eal_config_create();
            break;
        case RTE_PROC_SECONDARY:
            //从进程打开共享内存配置后，映射到从进程自己的地址空间
            rte_eal_config_attach();
            //睡眠等待主进程设置完成共享内存配置
            rte_eal_mcfg_wait_complete(rte_config.mem_config);
            //从进程重新映射共享内存配置
            rte_eal_config_reattach();
    }
}

//从进程打开/var/run/.rte_config文件
mem_cfg_fd = open(pathname, O_RDWR);
//从进程将/var/run/.rte_config文件内容映射到从进程空间
rte_mem_cfg_addr = mmap(NULL, sizeof(*rte_config.mem_config),PROT_READ | PROT_WRITE, MAP_SHARED, mem_cfg_fd, 0

思考个问题，dpdk如何保证在主从进程模式下，物理地址相同，对应的主从进程的虚拟地址也相同呢？答案是主进程mmap映射后，主进程会将mmap映射后的虚拟地址放到共享内存中rte_config.mem_config。从进程会进行2次共享内存映射，第一次调用mmap进行映射时，第一个参数为空，表示由内核选择一个虚拟地址空间，从进程将会映射到这个由内核选择的虚拟地址空间中，此时从进程就可以从共享内存中获取到主进程mmap后的虚拟地址。之后从进程第二次调用mmap进行映射，传递的第一个参数不为空了，而是主进程mmap映射后的虚拟地址，相当于从进程直接从这个虚拟地址开始映射，从而保证了主从进程的虚拟地址空间一样，对应的物理空间也一样。主从进程的映射逻辑，都在rte_config_init函数中
原文链接：https://blog.csdn.net/ApeLife/article/details/99700882



rte_malloc


eth_igb_dev_init
read register or write:
E1000_PCI_REG_ADDR
E1000_READ_REG
E1000_WRITE_REG

e1000_init_nvm_ops_generic
e1000_init_mbx_ops_generic -> mailbox

cb:
rx_pkt_burst



core:
rte_flow_create


从 find_physaddr() 中提取 rte_mem_virt2phy()。 该函数允许获取映射到调用该函数的当前进程的任何虚拟地址的物理地址。 请注意，此函数非常慢，不应在初始化后调用，以避免性能瓶颈
#define RTE_BAD_PHYS_ADDR ((phys_addr_t)-1)
#define RTE_BAD_IOVA ((rte_iova_t)-1)

rte_mem_virt2phy(const void *virtaddr) -> 获取当前进程中任意映射虚拟地址的物理地址, 整理了DPDK中实现在用户态分配巨页和获取巨页物理地址的代码，可以作为参考，需要简化代码
    page_size = getpagesize()


rte_iova_t rte_mem_virt2iova(const void *virt);

内存缓冲区
struct rte_mbuf {
    ...
    buf_iova -> 段缓冲区的物理地址。 如果构建配置为仅使用虚拟地址作为 IOVA（即 RTE_IOVA_AS_PA 为 0），则该字段未定义。 强制对齐到 8 字节，以确保 32 位和 64 位具有完全相同的 mbuf cacheline0 布局。 这使得矢量驱动程序的工作变得更加容易. buf_iova 是给设备用的地址，在 iova_mod=PA 的情况，buf_iova 就是物理地址
    ...
}


rte_mempool_obj_iter(mp, rte_pktmbuf_init, NULL) -> mbuf：使用配置中的默认内存池处理程序，默认情况下，用于 mbuf 分配的内存池操作是多生产者和多消费者环。 我们可以想象一个提供硬件辅助池机制的目标（也许是一些网络处理器？）。 在这种情况下，该架构的默认配置将包含不同的 RTE_MBUF_DEFAULT_MEMPOOL_OPS 值
    rte_pktmbuf_priv_size
    rte_pktmbuf_data_room_size
    rte_mbuf_iova_set(m, rte_mempool_virt2iova(m) + mbuf_size) -> mbuf：添加帮助程序来获取/设置 IOVA 地址，添加 API rte_mbuf_iova_set 和 rte_mbuf_iova_get 分别用于设置和获取 mbuf 的物理地址。 更新了应用程序和库以使用相同的


rte_mempool_populate_default


struct hugepage_info {



./dpdk-helloworld -l 0-3 -n 4





eal_get_virtual_area

echo 16 >/sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages
cat /proc/meminfo |grep -i huge

helloworld -> examples/helloworld/main.c
main(int argc, char **argv)
rte_eal_init(int argc, char **argv)
    rte_eal_get_configuration
    eal_get_internal_configuration
    rte_cpu_is_supported
        RTE_COMPILE_TIME_CPUFLAGS -> #define RTE_COMPILE_TIME_CPUFLAGS RTE_CPUFLAG_SSE,RTE_CPUFLAG_SSE2,RTE_CPUFLAG_SSE3,RTE_CPUFLAG_SSSE3,RTE_CPUFLAG_SSE4_1,RTE_CPUFLAG_SSE4_2,RTE_CPUFLAG_AES,RTE_CPUFLAG_AVX,RTE_CPUFLAG_AVX2,RTE_CPUFLAG_AVX512BW,RTE_CPUFLAG_AVX512CD,RTE_CPUFLAG_AVX512DQ,RTE_CPUFLAG_AVX512F,RTE_CPUFLAG_AVX512VL,RTE_CPUFLAG_PCLMULQDQ,RTE_CPUFLAG_RDRAND,RTE_CPUFLAG_RDSEED
        rte_cpu_get_flag_enabled
            rte_cpu_feature_table
            __get_cpuid_max(feat->leaf & 0x80000000, NULL)
            const struct feature_entry rte_cpu_feature_table[]
    __atomic_compare_exchange_n
    eal_reset_internal_config
        internal_cfg->iova_mode = RTE_IOVA_DC -> default memory mode
    eal_log_level_parse -> set_log demo: ./app/test-pmd --log-level='pmd\.i40e.*,8' -> 现在正确设置 --log-level=7 不会打印来自 rte_eal_cpu_init() 例程的消息
    eal_save_args -> Connecting to /var/run/dpdk/rte/dpdk_telemetry.v2
        handle_eal_info_request
            rte_tel_data_start_array
            rte_tel_data_add_array_string
    rte_eal_cpu_init -> eal：不要对CPU检测感到恐慌，可能没有办法优雅地恢复，但是应该通知应用程序发生了故障，而不是完全中止。 这允许用户继续使用“慢路径”类型的解决方案。 进行此更改后，EAL CPU NUMA 节点解析步骤不再发出 rte_panic。 这与 rte_eal_init 中的代码一致，该代码期望失败返回错误代码 -> 使用物理和逻辑处理器的数量填充配置 此函数是 EAL 专用的。 解析 /proc/cpuinfo 以获取计算机上的物理和逻辑处理器的数量, /sys/devices/system/cpu
        eal_cpu_socket_id -> NUMA_NODE_PATH "/sys/devices/system/node"
        eal_cpu_detected -> eal：不缓存 lcore 检测状态，我们仅在服务核心和 -c/-l 选项的控制路径中使用此状态。 使用--lcores 时，该值不会更新。 在需要的地方使用内部助手
    eal_parse_args
        while ((opt = getopt_long
        eal_parse_common_option
            -l 和 -c 选项是选择 DPDK 使用的内核的两种方法。 它们的格式不同，但对所选核心的检查是相同的。 使用中间数组将特定的解析检查与常见的一致性检查分开。 解析函数现在专注于验证传递的字符串，而不执行其他操作。 我们可以报告所有无效的核心索引，而不仅仅是第一个错误。 在错误日志消息中，当核心列表不连续时，将 [0, cfg->lcore_count - 1] 报告为有效范围是错误的
            eal_service_cores_parsed
            rte_eal_parse_coremask
            update_lcore_config
            -n -> conf->force_nchannel = atoi(optarg)
        eal_create_runtime_dir -> eal：即使不使用共享数据，也创建运行时目录，当不需要多进程并且DPDK使用“no-shconf”标志运行时，遥测库仍然需要一个运行时目录来放置用于遥测连接的unix套接字。 因此，我们可以更改代码以尝试创建目录，而不是在设置此标志时不创建目录，但如果失败则不会出错。 如果成功，则遥测将可用，但如果失败，DPDK 的其余部分将在没有遥测的情况下运行。 这确保了“内存中”标志将允许 DPDK 运行，即使整个文件系统是只读的
            /var/run/dpdk
            eal_get_hugefile_prefix
            eal_set_runtime_dir
                strlcpy(runtime_dir, run_dir, PATH_MAX) 
        eal_adjust_config
            eal_auto_detect_cores -> eal：限制核心自动检测，当未指定以下选项时，此补丁使用 pthread_getaffinity_np() 来缩小使用的核心范围： * coremask (-c) * corelist (-l) * 和 coremap (--lcores) 这样做的目的 patch的目的是在容器环境下部署DPDK应用程序时省略这些核心相关选项，以便用户在开发应用程序时不需要决定核心相关参数。 相反，当应用程序部署在容器中时，请使用 cpu-set 来限制可以在该容器实例内使用哪些核心。 而容器内的DPDK应用程序只是依靠这种自动检测机制来启动轮询线程。 注意：之前有部分用户使用隔离CPU，默认可以排除。 请添加任务集等命令来使用这些核心。 测试示例： $taskset 0xc0000 ./examples/helloworld/build/helloworld -m 1024
                rte_thread_get_affinity_by_id
            eal_proc_type_detect
            main_lcore_parsed -> eal：重命名lcore master和slave，将master lcore替换为main lcore，并将slave lcore替换为worker lcore。 保留旧函数和宏，但将它们标记为在此版本中已弃用。 “--master-lcore”命令行选项也已弃用，任何使用都会打印警告并使用“--main-lcore”作为替换
            compute_ctrl_threads_cpuset -> eal：限制控制线程启动 CPU 亲和力，在不属于 eal coremask 的任何内容上生成 ctrl 线程对系统的其余部分来说不太礼貌，尤其是当您非常小心地使用工具将进程固定在 cpu 资源上时 像任务集（linux）/cpuset（freebsd）。 我们不再引入另一个 eal 选项来控制在哪个 cpu 上创建这些 ctrl 线程，而是以启动 cpu 亲和力作为参考并从中删除 eal coremask。 如果没有剩下 cpu，那么我们默认为主核心。 cpuset 在 init 时计算一次，然后原始 cpu 关联性就会丢失。 引入了一个RTE_CPU_AND宏来抽象linux和freebsd各自宏之间的差异 -> taskset -c 7  ./master/app/testpmd --master-lcore 0 --lcores '(0,7)@(7,4,5)'  --no-huge --no-pci -m 512 -- -i --total-num-mbufs=2048
                RTE_CPU_AND
        eal_check_common_options -> sanity checks -> eal：分解选项健全性检查，无需对常见选项进行重复检查。 为选项 -c 和 -m 设置一些标志以简化检查
            Main lcore
            mbuf_pool ...
        eal_usage
            eal_common_usage -> help
    eal_plugins_init -> eal: 在设备解析之前调用插件 init，默认 eal_init 代码调用 0. eal_plugins_init 1. eal_option_device_parse 2. rte_bus_scan IOVA 提交：cf408c224 错过了在 eal_option_device_parse、rte_bus_scan 之前调用 eal_plugins_init 以及下面引入的共享模式回归：使用 CONFIG_RTE_BUILD_SHARED_LIB=y: 'net_vhost 0 ,iface=/tmp/vhost-user2' -d ./install/lib/librte_pmd_vhost.so -- --portmask=1 --disable-hw-vlan -i --rxq=1 --txq=1 --nb -cores=1 --eth-peer=0,52:54:00:11:22:12 EAL：检测到 4 个 lcore 错误：无法解析设备“net_vhost0”EAL：无法解析设备“net_vhost0,iface” =/tmp/vhost-user2' main() 中发生恐慌：无法初始化 EAL
        如果我们不是静态链接，请添加默认驱动程序加载路径（如果它作为目录存在）。 （在 EAL 上使用带有 NOLOAD 标志的 dlopen，如果 EAL 共享库尚未加载，即它是静态链接的，则将返回 NULL
        is_shared_build
            #define EAL_SO "librte_eal.so
            handle = dlopen(soname, RTLD_LAZY | RTLD_NOLOAD)
        eal_plugin_add -> eal：支持从目录加载驱动程序，添加对目录的支持作为 -d 的参数，以从给定目录加载所有驱动程序。 此外，可以在构建时配置中设置默认驱动程序目录，在这种情况下，在初始化 EAL 时将始终使用该目录。 与使用 -d 手动加载单个驱动程序相比，这大大简化了共享库配置的使用，并允许发行版建立一个嵌入式驱动程序目录，以便与第 3 方驱动程序等无缝集成
            -> #define RTE_EAL_PMD_PATH "/usr/local/lib/x86_64-linux-gnu/dpdk/pmds-23.1"
        TAILQ_FOREACH
            eal_plugindir_init
            eal_dlopen
    rte_config_init
        rte_eal_config_create
            mem_cfg_fd = open(pathname, O_RDWR | O_CREAT, 0600)
            retval = ftruncate(mem_cfg_fd, cfg_len)
            retval = fcntl(mem_cfg_fd, F_SETLK, &wr_lock)
            eal_get_virtual_area -> eal：修复多进程的内存配置分配，目前，内存配置将在不使用虚拟区域预留基础设施的情况下进行映射，这意味着它将被映射到任意位置。 这可能会导致在辅助进程中映射共享配置失败，因为 PCI 白名单参数在主进程已分配共享内存配置的空间中分配内存。 通过使用虚拟区域预留来为内存配置预留空间来修复此问题，从而避免该问题并保留共享配置（希望如此）远离任何正常的内存分配
                rte_mem_page_size -> eal：引入内存管理包装器，引入独立于操作系统的包装器，用于跨DPDK使用的内存管理操作，特别是在EAL的公共代码中： * rte_mem_map() * rte_mem_unmap() * rte_mem_page_size() * rte_mem_lock() Windows使用不同的API进行内存映射 和保留，而 Unices 通过映射来保留内存。 引入 EAL 私有函数以支持公共代码中的内存预留： * eal_mem_reserve() * eal_mem_free() * eal_mem_set_dump() 包装器遵循仅限于 DPDK 任务的 POSIX 语义，但它们的签名故意与 POSIX 签名不同，以更加安全和更具表现力。 新符号是内部的。 由于包装很薄，因此不需要特殊维护
                eal_get_baseaddr -> Linux 内核使用一个非常高的地址作为服务 mmap 调用的起始地址。 如果存在寻址限制并且 IOVA 模式为 VA，则该起始地址对于这些设备来说可能太高。 但是，可以在进程虚拟地址空间中使用较低的地址，因为 64 位有大量可用空间。 当前已知的限制是 39 或 40 位。 将起始地址设置为 4GB 意味着有 508GB 或 1020GB 用于映射可用的大页。 这对于大多数系统来说可能已经足够了，尽管具有寻址限制的设备应该调用 rte_mem_check_dma_mask 以确保所有内存都在支持的范围内
                    return 0x7000000000ULL -> 28GB = int("0x700000000", 16)/(1<<30)
                    or
                    return 0x100000000ULL -> 4GB
                eal_mem_reserve
                    int sys_flags = MAP_PRIVATE | MAP_ANONYMOUS;
                    sys_flags |= MAP_HUGETLB
                     mem_map(requested_addr, size, PROT_NONE, sys_flags, -1, 0)
                RTE_PTR_ALIGN
            mapped_mem_cfg_addr = mmap(rte_mem_cfg_addr,
			cfg_len_aligned, PROT_READ | PROT_WRITE,
			MAP_SHARED | MAP_FIXED, mem_cfg_fd, 0);
        eal_mcfg_update_from_internal
            mcfg->single_file_segments = internal_conf->single_file_segments
        rte_eal_config_attach
        eal_mcfg_wait_complete
        __rte_mp_enable
    rte_eal_using_phys_addrs -> eal：根据PA可用性计算IOVA模式，目前，如果总线选择IOVA作为PA，则在缺乏对物理地址的访问时，内存初始化可能会失败。 对于普通用户来说，这可能很难理解出了什么问题，因为这是默认行为。 通过验证物理地址可用性，在 eal init 中尽早发现这种情况，或者在没有表达明确的偏好时选择 IOVA。 总线代码已更改，以便它在不关心 IOVA 模式时进行报告，并让 eal init 决定。 在Linux实现中，重新设计rte_eal_using_phys_addrs()，以便可以更早地调用它，但仍然避免与rte_mem_virt2phys()的循环依赖。 在 FreeBSD 实现中，rte_eal_using_phys_addrs() 始终返回 false，因此检测部分保持原样。 如果编译了librte_kni并加载了KNI kmod， - 如果总线请求VA，如果物理地址可用，则强制使用PA，就像之前所做的那样， - 否则，将iova保留为VA，KNI init稍后将失败
        rte_eal_has_hugepages -> no_hugetlbfs -> default use hugepage
        rte_mem_virt2phy
            return RTE_BAD_IOVA
    rte_bus_get_iommu_class
    if (internal_conf->no_hugetlbfs == 0)
        hugepage_info_init
        create_shared_memory
            map_sharee_memory
    ...
    RTE_LOG(DEBUG, EAL, "IOMMU is not available, selecting IOVA as PA mode.\n")
    rte_eal_get_configuration
    eal_hugepage_info_init
    eal_log_init
    rte_eal_vfio_setup
    rte_eal_memzone_init
    eal_hugedirs_unlock
    rte_eal_malloc_heap_init
    rte_eal_tailqs_init
    rte_eal_timer_init
    eal_check_mem_on_local_socket
    rte_thread_set_affinity_by_id
    eal_thread_dump_current_affinity
    RTE_LCORE_FOREACH_WORKER(i)
        eal_worker_thread_create(i)
    rte_eal_mp_remote_launch sync_func
    rte_eal_mp_wait_lcore
    rte_service_init
    if (rte_bus_probe())
    rte_vfio_is_enabled
    rte_service_start_with_defaults
    eal_clean_runtime_dir
    rte_log_register_type_and_pick_level
    rte_telemetry_init
    eal_mcfg_complete
rte_eal_remote_launch(lcore_hello, NULL, lcore_id)
lcore_hello




args/option:
eal_usage
eal_common_usage(void)
{
    printf("[options]\n\n"
           "EAL common options:\n"
           "  -c COREMASK         Hexadecimal bitmask of cores to run on\n"
           "  -l CORELIST         List of cores to run on\n"
           "                      The argument format is <c1>[-c2][,c3[-c4],...]\n"
           "                      where c1, c2, etc are core indexes between 0 and %d\n"
           "  --"OPT_LCORES" COREMAP    Map lcore set to physical cpu set\n"
           "                      The argument format is\n"
           "                            '<lcores[@cpus]>[<,lcores[@cpus]>...]'\n"
           "                      lcores and cpus list are grouped by '(' and ')'\n"
           "                      Within the group, '-' is used for range separator,\n"
           "                      ',' is used for single number separator.\n"
           "                      '( )' can be omitted for single element group,\n"
           "                      '@' can be omitted if cpus and lcores have the same value\n"
           "  -s SERVICE COREMASK Hexadecimal bitmask of cores to be used as service cores\n"
           "  --"OPT_MAIN_LCORE" ID     Core ID that is used as main\n"
           "  --"OPT_MBUF_POOL_OPS_NAME" Pool ops name for mbuf to use\n"
           "  -n CHANNELS         Number of memory channels\n" -> 内存通道是内存单元和 CPU 之间用于数据移动的走线。 内存通道的数量充当以更快的速率传输数据的路径。 对于 OVS-DPDK，参数 OVSDpdkMemoryChannels 保存活动使用的通道数, 内存通道 获取正确的内存通道数（-n 参数）很棘手，因为它取决于系统主板支持的通道数、内存芯片的数量和类型以及它们在系统中的物理安装方式，并且没有简单或简单的方法 甚至可以通过可靠的方式来判断正在运行的系统。 此信息应该在 BIOS 内存检查阶段的启动期间可用，在运行时 dmidecode 可以帮助至少做出有根据的猜测。 除非已经安装，否则您现在需要这样做： # yum install dmidecode 这通常会提供足够的信息来查找系统和/或主板手册，以了解主板支持什么以及在哪些配置中内存插槽数量 对于多通道支持至关重要： # dmidecode -t system # dmidecode -t baseboard 这会输出系统上已填充的内存插槽： # dmidecode -t memory | grep 'Size: [0-9]' 如果只有一个，则不能使用多通道内存。 如果有两个或其倍数，则可能是双通道，如果有三个或其倍数，则可能是三通道，如果有四个或其倍数，则可能是四通道。 或者双通道...此外，内存设备的定位器字段中可能还有进一步的提示，例如 ChannelA-DIMM0 和 ChannelB-DIMM0： grep 定位器：
           "  -m MB               Memory to allocate (see also --"OPT_SOCKET_MEM")\n"
           "  -r RANKS            Force number of memory ranks (don't detect)\n"
           "  -b, --block         Add a device to the blocked list.\n"
           "                      Prevent EAL from using this device. The argument\n"
           "                      format for PCI devices is <domain:bus:devid.func>.\n"
           "  -a, --allow         Add a device to the allow list.\n"
           "                      Only use the specified devices. The argument format\n"
           "                      for PCI devices is <[domain:]bus:devid.func>.\n"
           "                      This option can be present several times.\n"
           "                      [NOTE: " OPT_DEV_ALLOW " cannot be used with "OPT_DEV_BLOCK" option]\n"
           "  --"OPT_VDEV"              Add a virtual device.\n"
           "                      The argument format is <driver><id>[,key=val,...]\n"
           "                      (ex: --vdev=net_pcap0,iface=eth2).\n"
           "  --"OPT_IOVA_MODE"   Set IOVA mode. 'pa' for IOVA_PA\n"
           "                      'va' for IOVA_VA\n"
           "  -d LIB.so|DIR       Add a driver or driver directory\n"
           "                      (can be used multiple times)\n"
           "  --"OPT_VMWARE_TSC_MAP"    Use VMware TSC map instead of native RDTSC\n"
           "  --"OPT_PROC_TYPE"         Type of this process (primary|secondary|auto)\n"
#ifndef RTE_EXEC_ENV_WINDOWS
           "  --"OPT_SYSLOG"            Set syslog facility\n"
#endif
           "  --"OPT_LOG_LEVEL"=<level> Set global log level\n"
           "  --"OPT_LOG_LEVEL"=<type-match>:<level>\n"
           "                      Set specific log level\n"
           "  --"OPT_LOG_LEVEL"=help    Show log types and levels\n"
#ifndef RTE_EXEC_ENV_WINDOWS
           "  --"OPT_TRACE"=<regex-match>\n"
           "                      Enable trace based on regular expression trace name.\n"
           "                      By default, the trace is disabled.\n"
           "		      User must specify this option to enable trace.\n"
           "  --"OPT_TRACE_DIR"=<directory path>\n"
           "                      Specify trace directory for trace output.\n"
           "                      By default, trace output will created at\n"
           "                      $HOME directory and parameter must be\n"
           "                      specified once only.\n"
           "  --"OPT_TRACE_BUF_SIZE"=<int>\n"
           "                      Specify maximum size of allocated memory\n"
           "                      for trace output for each thread. Valid\n"
           "                      unit can be either 'B|K|M' for 'Bytes',\n"
           "                      'KBytes' and 'MBytes' respectively.\n"
           "                      Default is 1MB and parameter must be\n"
           "                      specified once only.\n"
           "  --"OPT_TRACE_MODE"=<o[verwrite] | d[iscard]>\n"
           "                      Specify the mode of update of trace\n"
           "                      output file. Either update on a file can\n"
           "                      be wrapped or discarded when file size\n"
           "                      reaches its maximum limit.\n"
           "                      Default mode is 'overwrite' and parameter\n"
           "                      must be specified once only.\n"
#endif /* !RTE_EXEC_ENV_WINDOWS */
           "  -v                  Display version information on startup\n"
           "  -h, --help          This help\n"
           "  --"OPT_IN_MEMORY"   Operate entirely in memory. This will\n"
           "                      disable secondary process support\n"
           "  --"OPT_BASE_VIRTADDR"     Base virtual address\n"
           "  --"OPT_TELEMETRY"   Enable telemetry support (on by default)\n"
           "  --"OPT_NO_TELEMETRY"   Disable telemetry support\n"
           "  --"OPT_FORCE_MAX_SIMD_BITWIDTH" Force the max SIMD bitwidth\n"
           "\nEAL options for DEBUG use only:\n"
           "  --"OPT_HUGE_UNLINK"[=existing|always|never]\n"
           "                      When to unlink files in hugetlbfs\n"
           "                      ('existing' by default, no value means 'always')\n"
           "  --"OPT_NO_HUGE"           Use malloc instead of hugetlbfs\n"
           "  --"OPT_NO_PCI"            Disable PCI\n"
           "  --"OPT_NO_HPET"           Disable HPET\n"
           "  --"OPT_NO_SHCONF"         No shared config (mmap'd files)\n"
           "\n", RTE_MAX_LCORE);
}



CPU特性
const struct feature_entry rte_cpu_feature_table[] = {
    FEAT_DEF(SSE3, 0x00000001, 0, RTE_REG_ECX,  0)
    FEAT_DEF(PCLMULQDQ, 0x00000001, 0, RTE_REG_ECX,  1)
    FEAT_DEF(DTES64, 0x00000001, 0, RTE_REG_ECX,  2)
    FEAT_DEF(MONITOR, 0x00000001, 0, RTE_REG_ECX,  3)
    FEAT_DEF(DS_CPL, 0x00000001, 0, RTE_REG_ECX,  4)
    FEAT_DEF(VMX, 0x00000001, 0, RTE_REG_ECX,  5)
    FEAT_DEF(SMX, 0x00000001, 0, RTE_REG_ECX,  6)
    FEAT_DEF(EIST, 0x00000001, 0, RTE_REG_ECX,  7)
    FEAT_DEF(TM2, 0x00000001, 0, RTE_REG_ECX,  8)
    FEAT_DEF(SSSE3, 0x00000001, 0, RTE_REG_ECX,  9)
    FEAT_DEF(CNXT_ID, 0x00000001, 0, RTE_REG_ECX, 10)
    FEAT_DEF(FMA, 0x00000001, 0, RTE_REG_ECX, 12)
    FEAT_DEF(CMPXCHG16B, 0x00000001, 0, RTE_REG_ECX, 13)
    FEAT_DEF(XTPR, 0x00000001, 0, RTE_REG_ECX, 14)
    FEAT_DEF(PDCM, 0x00000001, 0, RTE_REG_ECX, 15)
    FEAT_DEF(PCID, 0x00000001, 0, RTE_REG_ECX, 17)
    FEAT_DEF(DCA, 0x00000001, 0, RTE_REG_ECX, 18)
    FEAT_DEF(SSE4_1, 0x00000001, 0, RTE_REG_ECX, 19)
    FEAT_DEF(SSE4_2, 0x00000001, 0, RTE_REG_ECX, 20)
    FEAT_DEF(X2APIC, 0x00000001, 0, RTE_REG_ECX, 21)
    FEAT_DEF(MOVBE, 0x00000001, 0, RTE_REG_ECX, 22)
    FEAT_DEF(POPCNT, 0x00000001, 0, RTE_REG_ECX, 23)
    FEAT_DEF(TSC_DEADLINE, 0x00000001, 0, RTE_REG_ECX, 24)
    FEAT_DEF(AES, 0x00000001, 0, RTE_REG_ECX, 25)
    FEAT_DEF(XSAVE, 0x00000001, 0, RTE_REG_ECX, 26)
    FEAT_DEF(OSXSAVE, 0x00000001, 0, RTE_REG_ECX, 27)
    FEAT_DEF(AVX, 0x00000001, 0, RTE_REG_ECX, 28)
    FEAT_DEF(F16C, 0x00000001, 0, RTE_REG_ECX, 29)
    FEAT_DEF(RDRAND, 0x00000001, 0, RTE_REG_ECX, 30)
    FEAT_DEF(HYPERVISOR, 0x00000001, 0, RTE_REG_ECX, 31)

    FEAT_DEF(FPU, 0x00000001, 0, RTE_REG_EDX,  0)
    FEAT_DEF(VME, 0x00000001, 0, RTE_REG_EDX,  1)
    FEAT_DEF(DE, 0x00000001, 0, RTE_REG_EDX,  2)
    FEAT_DEF(PSE, 0x00000001, 0, RTE_REG_EDX,  3)
    FEAT_DEF(TSC, 0x00000001, 0, RTE_REG_EDX,  4)
    FEAT_DEF(MSR, 0x00000001, 0, RTE_REG_EDX,  5)
    FEAT_DEF(PAE, 0x00000001, 0, RTE_REG_EDX,  6)
    FEAT_DEF(MCE, 0x00000001, 0, RTE_REG_EDX,  7)
    FEAT_DEF(CX8, 0x00000001, 0, RTE_REG_EDX,  8)
    FEAT_DEF(APIC, 0x00000001, 0, RTE_REG_EDX,  9)
    FEAT_DEF(SEP, 0x00000001, 0, RTE_REG_EDX, 11)
    FEAT_DEF(MTRR, 0x00000001, 0, RTE_REG_EDX, 12)
    FEAT_DEF(PGE, 0x00000001, 0, RTE_REG_EDX, 13)
    FEAT_DEF(MCA, 0x00000001, 0, RTE_REG_EDX, 14)
    FEAT_DEF(CMOV, 0x00000001, 0, RTE_REG_EDX, 15)
    FEAT_DEF(PAT, 0x00000001, 0, RTE_REG_EDX, 16)
    FEAT_DEF(PSE36, 0x00000001, 0, RTE_REG_EDX, 17)
    FEAT_DEF(PSN, 0x00000001, 0, RTE_REG_EDX, 18)
    FEAT_DEF(CLFSH, 0x00000001, 0, RTE_REG_EDX, 19)
    FEAT_DEF(DS, 0x00000001, 0, RTE_REG_EDX, 21)
    FEAT_DEF(ACPI, 0x00000001, 0, RTE_REG_EDX, 22)
    FEAT_DEF(MMX, 0x00000001, 0, RTE_REG_EDX, 23)
    FEAT_DEF(FXSR, 0x00000001, 0, RTE_REG_EDX, 24)
    FEAT_DEF(SSE, 0x00000001, 0, RTE_REG_EDX, 25)
    FEAT_DEF(SSE2, 0x00000001, 0, RTE_REG_EDX, 26)
    FEAT_DEF(SS, 0x00000001, 0, RTE_REG_EDX, 27)
    FEAT_DEF(HTT, 0x00000001, 0, RTE_REG_EDX, 28)
    FEAT_DEF(TM, 0x00000001, 0, RTE_REG_EDX, 29)
    FEAT_DEF(PBE, 0x00000001, 0, RTE_REG_EDX, 31)

    FEAT_DEF(DIGTEMP, 0x00000006, 0, RTE_REG_EAX,  0)
    FEAT_DEF(TRBOBST, 0x00000006, 0, RTE_REG_EAX,  1)
    FEAT_DEF(ARAT, 0x00000006, 0, RTE_REG_EAX,  2)
    FEAT_DEF(PLN, 0x00000006, 0, RTE_REG_EAX,  4)
    FEAT_DEF(ECMD, 0x00000006, 0, RTE_REG_EAX,  5)
    FEAT_DEF(PTM, 0x00000006, 0, RTE_REG_EAX,  6)

    FEAT_DEF(MPERF_APERF_MSR, 0x00000006, 0, RTE_REG_ECX,  0)
    FEAT_DEF(ACNT2, 0x00000006, 0, RTE_REG_ECX,  1)
    FEAT_DEF(ENERGY_EFF, 0x00000006, 0, RTE_REG_ECX,  3)

    FEAT_DEF(FSGSBASE, 0x00000007, 0, RTE_REG_EBX,  0)
    FEAT_DEF(BMI1, 0x00000007, 0, RTE_REG_EBX,  3)
    FEAT_DEF(HLE, 0x00000007, 0, RTE_REG_EBX,  4)
    FEAT_DEF(AVX2, 0x00000007, 0, RTE_REG_EBX,  5)
    FEAT_DEF(SMEP, 0x00000007, 0, RTE_REG_EBX,  7)
    FEAT_DEF(BMI2, 0x00000007, 0, RTE_REG_EBX,  8)
    FEAT_DEF(ERMS, 0x00000007, 0, RTE_REG_EBX,  9)
    FEAT_DEF(INVPCID, 0x00000007, 0, RTE_REG_EBX, 10)
    FEAT_DEF(RTM, 0x00000007, 0, RTE_REG_EBX, 11)
    FEAT_DEF(AVX512F, 0x00000007, 0, RTE_REG_EBX, 16)
    FEAT_DEF(AVX512DQ, 0x00000007, 0, RTE_REG_EBX, 17)
    FEAT_DEF(RDSEED, 0x00000007, 0, RTE_REG_EBX, 18)
    FEAT_DEF(AVX512IFMA, 0x00000007, 0, RTE_REG_EBX, 21)
    FEAT_DEF(AVX512CD, 0x00000007, 0, RTE_REG_EBX, 28)
    FEAT_DEF(AVX512BW, 0x00000007, 0, RTE_REG_EBX, 30)
    FEAT_DEF(AVX512VL, 0x00000007, 0, RTE_REG_EBX, 31)

    FEAT_DEF(AVX512VBMI, 0x00000007, 0, RTE_REG_ECX,  1)
    FEAT_DEF(WAITPKG, 0x00000007, 0, RTE_REG_ECX,  5)
    FEAT_DEF(AVX512VBMI2, 0x00000007, 0, RTE_REG_ECX,  6)
    FEAT_DEF(GFNI, 0x00000007, 0, RTE_REG_ECX,  8)
    FEAT_DEF(VAES, 0x00000007, 0, RTE_REG_ECX,  9)
    FEAT_DEF(VPCLMULQDQ, 0x00000007, 0, RTE_REG_ECX, 10)
    FEAT_DEF(AVX512VNNI, 0x00000007, 0, RTE_REG_ECX, 11)
    FEAT_DEF(AVX512BITALG, 0x00000007, 0, RTE_REG_ECX, 12)
    FEAT_DEF(AVX512VPOPCNTDQ, 0x00000007, 0, RTE_REG_ECX, 14)
    FEAT_DEF(CLDEMOTE, 0x00000007, 0, RTE_REG_ECX, 25)
    FEAT_DEF(MOVDIRI, 0x00000007, 0, RTE_REG_ECX, 27)
    FEAT_DEF(MOVDIR64B, 0x00000007, 0, RTE_REG_ECX, 28)

    FEAT_DEF(AVX512VP2INTERSECT, 0x00000007, 0, RTE_REG_EDX,  8)

    FEAT_DEF(LAHF_SAHF, 0x80000001, 0, RTE_REG_ECX,  0)
    FEAT_DEF(LZCNT, 0x80000001, 0, RTE_REG_ECX,  4)

    FEAT_DEF(SYSCALL, 0x80000001, 0, RTE_REG_EDX, 11)
    FEAT_DEF(XD, 0x80000001, 0, RTE_REG_EDX, 20)
    FEAT_DEF(1GB_PG, 0x80000001, 0, RTE_REG_EDX, 26)
    FEAT_DEF(RDTSCP, 0x80000001, 0, RTE_REG_EDX, 27)
    FEAT_DEF(EM64T, 0x80000001, 0, RTE_REG_EDX, 29)

    FEAT_DEF(INVTSC, 0x80000007, 0, RTE_REG_EDX,  8)
};



长短选项:
enum {
	/* long options mapped to a short option */
#define OPT_HELP              "help"
	OPT_HELP_NUM            = 'h',
#define OPT_DEV_ALLOW	      "allow"
	OPT_DEV_ALLOW_NUM       = 'a',
#define OPT_DEV_BLOCK         "block"
	OPT_DEV_BLOCK_NUM      = 'b',

	/* first long only option value must be >= 256, so that we won't
	 * conflict with short options */
	OPT_LONG_MIN_NUM = 256,
#define OPT_BASE_VIRTADDR     "base-virtaddr"
	OPT_BASE_VIRTADDR_NUM,
#define OPT_CREATE_UIO_DEV    "create-uio-dev"
	OPT_CREATE_UIO_DEV_NUM,
#define OPT_FILE_PREFIX       "file-prefix"
	OPT_FILE_PREFIX_NUM,
#define OPT_HUGE_DIR          "huge-dir"
	OPT_HUGE_DIR_NUM,
#define OPT_HUGE_UNLINK       "huge-unlink"
	OPT_HUGE_UNLINK_NUM,
#define OPT_LCORES            "lcores"
	OPT_LCORES_NUM,
#define OPT_LOG_LEVEL         "log-level"
	OPT_LOG_LEVEL_NUM,
#define OPT_TRACE             "trace"
	OPT_TRACE_NUM,
#define OPT_TRACE_DIR         "trace-dir"
	OPT_TRACE_DIR_NUM,
#define OPT_TRACE_BUF_SIZE    "trace-bufsz"
	OPT_TRACE_BUF_SIZE_NUM,
#define OPT_TRACE_MODE        "trace-mode"
	OPT_TRACE_MODE_NUM,
#define OPT_MAIN_LCORE        "main-lcore"
	OPT_MAIN_LCORE_NUM,
#define OPT_MBUF_POOL_OPS_NAME "mbuf-pool-ops-name"
	OPT_MBUF_POOL_OPS_NAME_NUM,
#define OPT_PROC_TYPE         "proc-type"
	OPT_PROC_TYPE_NUM,
#define OPT_NO_HPET           "no-hpet"
	OPT_NO_HPET_NUM,
#define OPT_NO_HUGE           "no-huge"
	OPT_NO_HUGE_NUM,
#define OPT_NO_PCI            "no-pci"
	OPT_NO_PCI_NUM,
#define OPT_NO_SHCONF         "no-shconf"
	OPT_NO_SHCONF_NUM,
#define OPT_IN_MEMORY         "in-memory"
	OPT_IN_MEMORY_NUM,
#define OPT_SOCKET_MEM        "socket-mem"
	OPT_SOCKET_MEM_NUM,
#define OPT_SOCKET_LIMIT        "socket-limit"
	OPT_SOCKET_LIMIT_NUM,
#define OPT_SYSLOG            "syslog"
	OPT_SYSLOG_NUM,
#define OPT_VDEV              "vdev"
	OPT_VDEV_NUM,
#define OPT_VFIO_INTR         "vfio-intr"
	OPT_VFIO_INTR_NUM,
#define OPT_VFIO_VF_TOKEN     "vfio-vf-token"
	OPT_VFIO_VF_TOKEN_NUM,
#define OPT_VMWARE_TSC_MAP    "vmware-tsc-map"
	OPT_VMWARE_TSC_MAP_NUM,
#define OPT_LEGACY_MEM    "legacy-mem"
	OPT_LEGACY_MEM_NUM,
#define OPT_SINGLE_FILE_SEGMENTS    "single-file-segments"
	OPT_SINGLE_FILE_SEGMENTS_NUM,
#define OPT_IOVA_MODE          "iova-mode"
	OPT_IOVA_MODE_NUM,
#define OPT_MATCH_ALLOCATIONS  "match-allocations"
	OPT_MATCH_ALLOCATIONS_NUM,
#define OPT_TELEMETRY         "telemetry"
	OPT_TELEMETRY_NUM,
#define OPT_NO_TELEMETRY      "no-telemetry"
	OPT_NO_TELEMETRY_NUM,
#define OPT_FORCE_MAX_SIMD_BITWIDTH  "force-max-simd-bitwidth"
	OPT_FORCE_MAX_SIMD_BITWIDTH_NUM,
#define OPT_HUGE_WORKER_STACK  "huge-worker-stack"
	OPT_HUGE_WORKER_STACK_NUM,

	OPT_LONG_MAX_NUM
};



设置日志级别:
export RTE_LOG_LEVEL=8


eal_dynmem_memseg_lists_init
计算出我们将拥有的内存量是一个漫长且非常复杂的过程。 我们操作的基本元素是内存类型，定义为 NUMA 节点 ID 和页面大小的组合（例如，具有 2 个页面大小的 2 个套接字总共产生 4 个内存类型）。 决定每种内存类型的内存量是每种类型的最大段、每种类型的最大内存和检测到的 NUMA 节点数量之间的平衡行为。 目标是确保每种内存类型至少获得一个 memseg 列表。 内存总量受 RTE_MAX_MEM_MB 值限制。 每种类型的内存总量受 RTE_MAX_MEM_MB_PER_TYPE 或 RTE_MAX_MEM_MB 除以检测到的 NUMA 节点数的限制。 此外，每种类型的最大段数也受到 RTE_MAX_MEMSEG_PER_TYPE 的限制。 这是因为对于较小的页面大小，可能需要数十万个段才能达到上述指定的每种类型的内存限制。 此外，每种类型可能有多个与其关联的 memseg 列表，每个列表受 RTE_MAX_MEM_MB_PER_LIST（对于较大的页面大小）或 RTE_MAX_MEMSEG_PER_LIST 段（对于较小的页面大小）的限制。 每种类型的 memseg 列表的数量是根据上述限制决定的，并且还考虑检测到的 NUMA 节点的数量，以确保在用内存填充所有 NUMA 节点之前我们不会用完 memseg 列表。 我们分三个阶段进行。 首先，我们收集类型的数量。 然后，我们找出内存限制并填充可能的 memseg 列表。 然后，我们继续分配 memseg 列表





helloworld -> examples/helloworld/main.c
main(int argc, char **argv)
rte_eal_init
    rte_eal_get_configuration
    eal_get_internal_configuration
    rte_cpu_is_supported
    eal_reset_internal_config
    eal_log_level_parse
    eal_save_args
    rte_eal_cpu_init
    eal_parse_args
    eal_plugins_init
    ...
    rte_config_init
        ...
        pathname -> /run/user/1020/dpdk/rte/config
        ...
        eal_mem_reserve
            addr:0x100000000 size: 28672
            ...
            mmap(requested_addr, size, prot, flags, fd, offset);
    rte_eal_using_phys_addrs
        rte_eal_has_hugepages -> no_hugetlbfs -> default use hugepage
        rte_mem_virt2phy
            return RTE_BAD_IOVA
    rte_bus_get_iommu_class
    if (internal_conf->no_hugetlbfs == 0)
        hugepage_info_init
        create_shared_memory
rte_eal_remote_launch(lcore_hello, NULL, lcore_id)
lcore_hello



rte_eal_malloc_heap_init
    malloc_add_seg


RTE_LCORE_FOREACH_WORKER(i)
    pipe(lcore_config[i].pipe_main2worker
    eal_worker_thread_create
        if (pthread_create(&lcore_config[lcore_id].thread_id, attrp, eal_thread_loop, (void *)(uintptr_t)lcore_id) == 0)
            eal_thread_wait_command
                n = read(m2w, &c, 1);
            eal_thread_ack_command
                n = write(w2m, &c, 1) <- eal_thread_wake_worker
    pthread_setaffinity_np
    rte_eal_mp_remote_launch(sync_func, NULL, SKIP_MAIN)
        rte_eal_remote_launch(f, arg, lcore_id)
            __atomic_store_n(&lcore_config[worker_id].f, f, __ATOMIC_RELEASE)
            eal_thread_wake_worker
    rte_eal_mp_wait_lcore


rte_service_init
    rte_services = rte_calloc("rte_services",



vfio_mp_sync_setup
    rte_mp_action_register
        name: eal_vfio_mp_sync
        entry = malloc(sizeof(struct action_entry));
        find_action_entry_by_name
        TAILQ_INSERT_TAIL(&action_entry_list, entry, next)


rte_service_start_with_defaults

eal_clean_runtime_dir





EAL: Multi-process socket /var/run/dpdk/rte/mp_socket


pci_probe(void)
    FOREACH_DEVICE_ON_PCIBUS <- RTE_PMD_REGISTER_PCI -> register pci device
        pci_probe_all_drivers
            FOREACH_DRIVER_ON_PCIBUS
                rte_pci_probe_one_driver
                    rte_pci_match
                    ...
                    hisi_dma_pmd_drv
                    idxd_pmd_drv_pci
                    ioat_pmd_drv
                    rte_ark_pmd
                    rte_cxgbe_pmd
                    rte_igb_pmd
                    rte_ice_pmd
                    mlx5_common_pci_driver <- rte_pci_register(&mlx5_common_pci_driver);
                    rte_virtio_net_pci_pmd
                    ...
                    ret = dr->probe(dr, dev) -> mlx5_common_pci_probe
                        mlx5_common_dev_probe
                            mlx5_kvargs_prepare
                            parse_class_options
                            mlx5_common_dev_create
                            is_valid_class_combination
                            drivers_probe
                                ...
                                mlx5_os_pci_probe
                                    mlx5_os_parse_eth_devargs
                                        rte_eth_devargs_parse
                                            eth_dev_devargs_tokenise
                                            rte_eth_devargs_parse_representor_ports
                                    if (eth_da.nb_ports > 0)
                                        mlx5_os_pci_probe_pf
                                            ibv_list = mlx5_glue->get_device_list(&ret)
                                            NETLINK_ROUTE
                                            NETLINK_RDMA
                                            mlx5_device_bond_pci_match
                                            np = mlx5_nl_portnum(nl_rdma, ibv_match[0]->name)
                                            mlx5_dev_spawn
                                            rte_eth_copy_pci_info
                                            rte_intr_instance_alloc
                                    else mlx5_os_pci_probe_pf
                                        mlx5_dev_spawn
                                            rte_eth_switch_domain_alloc



drivers/common/mlx5/mlx5_common_pci.c


mlx5_os_get_ibv_dev
mlx5_os_get_ibv_device


rte_telemetry_init
    telemetry_v2_init
        rte_telemetry_register_cmd("/"
            callbacks[i].fn = fn
        rte_telemetry_register_cmd("/info"
        v2_socket.sock = create_socket(v2_socket.path)
        pthread_create(&t_new, NULL, socket_listener, &v2_socket)
            int s_accepted = accept(s->sock, NULL, NULL)
            pthread_create(&th, NULL, s->fn,
    or telemetry_legacy_init



rte_log_register_type_and_pick_level


eal_mcfg_complete
    internal_conf->init_complete = 1;



RTE_PMD_REGISTER_VDEV(net_virtio_user, virtio_user_driver)
static struct rte_vdev_driver virtio_user_driver = {
	.probe = virtio_user_pmd_probe,
	.remove = virtio_user_pmd_remove,
	.dma_map = virtio_user_pmd_dma_map,
	.dma_unmap = virtio_user_pmd_dma_unmap,
};

vdpa
https://www.redhat.com/en/blog/vdpa-kernel-framework-part-3-usage-vms-and-containers
host模拟出/dev/vhost-vdpa0设备，容器中的testpmd接管设备，使用virtio-user driver
testpmd接管参考命令如下
./dpdk-testpmd -l 2-3 -n 4 --file-prefix=test --vdev=net_virtio_user0,path=/dev/vhost-vdpa-0,queues=1 – --forward-mode=sim -i -a

testpmd_funcs.rst, https://dpdk.readthedocs.io/en/v1.8.0/testpmd_app_ug/testpmd_funcs.html
user guider: https://doc.dpdk.org/guides/testpmd_app_ug/
run app: https://doc.dpdk.org/guides/testpmd_app_ug/run_app.html
./dpdk-testpmd -l 0-3 -n 4 -- -i --portmask=0x1 --nb-cores=2
app\test-pmd\testpmd.c -> main, https://blog.csdn.net/hhd1988/article/details/123237172, virtio-user pmd driver 跟 host 协商过程: https://blog.csdn.net/jyshappy/article/details/126718739
    rte_eal_init
        rte_bus_probe
            ret = bus->probe()
            vbus->probe() -> vdev_probe
                vdev_probe_all_drivers
                    driver->probe(dev) -> virtio_user_pmd_probe
                        eth_virtio_dev_init
                            virtio_init_device
                                virtio_set_status(hw, VIRTIO_CONFIG_STATUS_ACK)
                                virtio_set_status(hw, VIRTIO_CONFIG_STATUS_DRIVER)
                                virtio_ethdev_negotiate_features
                                    host_features = VIRTIO_OPS(hw)->get_features(hw)
                        virtio_user_dev_init
                            virtio_dev_construct(vdev, name, &virtio_user_ops, dev)
    register_eth_event_callback
    init_port
    set_def_fwd_config
    launch_args_parse
    rte_dev_hotplug_handle_enable
    rte_dev_event_monitor_start
    rte_dev_event_callback_register dev_event_callback
    start_port
    rte_eth_promiscuous_enable
    start_packet_forwarding
    rte_eal_cleanup


static const struct virtio_dev_ops virtio_user_ops = {
    .read_dev_cfg	= virtio_user_read_dev_config,
    .write_dev_cfg	= virtio_user_write_dev_config,
    .get_status	= virtio_user_get_status,
    .set_status	= virtio_user_set_status,
        virtio_user_dev_set_status(dev, status)
            ret = dev->ops->set_status(dev, status)
    .get_features	= virtio_user_get_features,
    .set_features	= virtio_user_set_features,
    .destruct_dev	= virtio_user_destroy,
    .get_queue_size	= virtio_user_get_queue_size,
    .setup_queue	= virtio_user_setup_queue,
    .del_queue	= virtio_user_del_queue,
    .notify_queue	= virtio_user_notify_queue,
    .dump_json_info = virtio_user_dump_json_info,
    .write_json_config = virtio_user_write_json_config,
};


struct fwd_engine io_fwd_engine = {
	.fwd_mode_name  = "io",
	.port_fwd_begin = NULL,
	.port_fwd_end   = NULL,
	.stream_init    = stream_init_forward,
	.packet_fwd     = pkt_burst_io_forward,
};

struct fwd_engine mac_fwd_engine = {
	.fwd_mode_name  = "mac",
	.port_fwd_begin = NULL,
	.port_fwd_end   = NULL,
	.stream_init    = stream_init_mac_forward,
	.packet_fwd     = pkt_burst_mac_forward,
};



struct fwd_engine mac_swap_engine = {
	.fwd_mode_name  = "macswap",
	.port_fwd_begin = NULL,
	.port_fwd_end   = NULL,
	.stream_init    = stream_init_mac_swap,
	.packet_fwd     = pkt_burst_mac_swap,
};


testpmd> show port info 0
cmdline_parse_inst_t cmd_showport = {
               .f =cmd_showport_parsed,
               .data =NULL,
               .help_str= "show|clear port "
                              "info|stats|xstats|fdir|stat_qmap|dcb_tc|cap"
                              "<port_id>",
               .tokens= {
                              (void*)&cmd_showport_show,
                              (void*)&cmd_showport_port,
                              (void*)&cmd_showport_what,
                              (void*)&cmd_showport_portnum,
                              NULL,
               },
};




./dpdk-vdpa -c 0x2 -n 4 --socket-mem 1024,1024 \
        -a 0000:06:00.3,vdpa=1 -a 0000:06:00.4,vdpa=1 \
        -- --interactive
or
./dpdk-vdpa -c 0x2 -n 4 --socket-mem 1024,1024 -w 0000:06:00.3,vdpa=1 -w 0000:06:00.4,vdpa=1

dpdk/examples/vdpa/main.c
    ret = rte_eal_init(argc, argv)
    cl = cmdline_stdin_new(main_ctx, "vdpa> ")
    cmdline_interact(cl)
        cmdline_read_char
        cmdline_in
            rdline_add_history(&cl->rdl, buffer)
                cirbuf_add_buf_tail(&rdl->history, buf, len) -> vhost_user_msg_handler
                cirbuf_add_tail(&rdl->history, 0)
    or start_vdpa(&vports[devcnt])
        rte_vhost_driver_register(socket_path, vport->flags)
        rte_vhost_driver_callback_register(socket_path,	&vdpa_sample_devops)
        rte_vhost_driver_attach_vdpa_device(socket_path, vport->dev)
            vsocket->vdpa_dev = dev -> 将vDPA的deviceid记录在vsocket结构中，这样就将vhost和vDPA设备关联起来
        rte_vhost_driver_get_vdpa_dev_type
        RTE_VHOST_VDPA_DEVICE_TYPE_BLK
            vdpa_blk_device_set_features_and_protocol
                rte_vhost_driver_set_features(path, VHOST_BLK_FEATURES)
                rte_vhost_driver_disable_features
                rte_vhost_driver_get_protocol_features
                    vdpa_dev->ops->get_protocol_features
                rte_vhost_driver_set_protocol_features
                    vsocket->protocol_features = protocol_features
        rte_vhost_driver_start(socket_path)

static const struct rte_vhost_device_ops vdpa_sample_devops = {
        rte_vhost_get_ifname(vid, ifname, sizeof(ifname))
	.new_device = new_device,
        dev = rte_vdpa_get_rte_device(vports[i].dev)
            return vdpa_dev->device
	.destroy_device = destroy_device,
};


vdpa> list
device id       device address  queue num       supported features
0               0000:06:00.3    1               0x14c238020
1               0000:06:00.4    1               0x14c238020
2               0000:06:00.5    1               0x14c238020
vdpa> create /tmp/vdpa-socket0 0000:06:00.3


-w
RTE_INIT(rte_mlx5_vdpa_init)
    mlx5_common_init()
        mlx5_glue_constructor
            setenv("RDMAV_HUGEPAGES_SAFE", "1", 1)
            setenv("MLX5_CQE_SIZE", "128", 0)
            setenv("MLX5_DEVICE_FATAL_CLEANUP", "1", 1)
        mlx5_common_driver_init
            mlx5_common_pci_init
    mlx5_class_driver_register(&mlx5_vdpa_driver)
static struct mlx5_class_driver mlx5_vdpa_driver = {
	.drv_class = MLX5_CLASS_VDPA,
	.name = RTE_STR(MLX5_VDPA_DRIVER_NAME),
	.id_table = mlx5_vdpa_pci_id_map,
	.probe = mlx5_vdpa_dev_probe,
        mlx5_vdpa_config_get(mkvlist, priv)
        mlx5_vdpa_create_dev_resources
        priv->vdev = rte_vdpa_register_device(cdev->dev, &mlx5_vdpa_ops)
	.remove = mlx5_vdpa_dev_remove,
};



vhost-user -> vdpa, 如: 通过virtio-net的vdpa_dev_id获取到对应的vDPA设备，并调用对应的vDPA的set_features函数
static struct rte_vdpa_dev_ops mlx5_vdpa_ops = {
	.get_queue_num = mlx5_vdpa_get_queue_num,
        *queue_num = priv->caps.max_num_virtio_queues / 2
	.get_features = mlx5_vdpa_get_vdpa_features,
        *features = MLX5_VDPA_DEFAULT_FEATURES
	.get_protocol_features = mlx5_vdpa_get_protocol_features,
        *features = MLX5_VDPA_PROTOCOL_FEATURES
	.dev_conf = mlx5_vdpa_dev_config,
	.dev_close = mlx5_vdpa_dev_close,
        rte_ring_enqueue_bulk_elem_start -> 开始将几个对象放入环中。请注意，此函数不会将任何实际对象放入队列中，它只是为用户保留了这种能力。用户必须调用适当的 enqueue_elem_finish() 将对象复制到队列中并完成给定的入队操作
        rte_ring_enqueue_elem_finish(r, obj, sizeof(struct mlx5_vdpa_task), n) -> 完成将多个对象加入环中。请注意，加入队列的对象数量不应超过先前 enqueue_start 返回的值。
	.dev_cleanup = mlx5_vdpa_dev_cleanup,
	.set_vring_state = mlx5_vdpa_set_vring_state,
	.set_features = mlx5_vdpa_features_set,
        if (RTE_VHOST_NEED_LOG(features))
            rte_vhost_get_negotiated_features
            rte_vhost_get_log_base
            mlx5_vdpa_dirty_bitmap_set
                mlx5_os_wrapped_mkey_create
                mlx5_devx_cmd_modify_virtq
            mlx5_vdpa_logging_enable
	.migration_done = NULL,
	.get_vfio_group_fd = NULL,
	.get_vfio_device_fd = mlx5_vdpa_get_device_fd,
	.get_notify_area = mlx5_vdpa_get_notify_area,
	.get_stats_names = mlx5_vdpa_get_stats_names,
	.get_stats = mlx5_vdpa_get_stats,
	.reset_stats = mlx5_vdpa_reset_stats,
};

VDPA设备操作:
struct rte_vdpa_dev_ops {



helloworld -> examples/helloworld/main.c
main(int argc, char **argv)
rte_eal_init
    rte_eal_get_configuration
    eal_get_internal_configuration
    rte_cpu_is_supported
    eal_reset_internal_config
    eal_log_level_parse
    eal_save_args
    rte_eal_cpu_init
    eal_parse_args
    eal_plugins_init
    ...
    rte_config_init
        ...
        pathname -> /run/user/1020/dpdk/rte/config
        ...
        eal_mem_reserve
            addr:0x100000000 size: 28672
            ...
            mmap(requested_addr, size, prot, flags, fd, offset);
    rte_eal_using_phys_addrs
        rte_eal_has_hugepages -> no_hugetlbfs -> default use hugepage
        rte_mem_virt2phy
            return RTE_BAD_IOVA
    rte_bus_get_iommu_class
    if (internal_conf->no_hugetlbfs == 0)
        hugepage_info_init
        create_shared_memory
rte_eal_remote_launch(lcore_hello, NULL, lcore_id)
lcore_hello


map_all_hugepages




map_shared_memory
    open(filename, flags, 0600)
    ftruncate(fd, mem_size)
    retval = mmap(NULL, mem_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);


eal_log_init
    log_stream = fopencookie(NULL, "w+", console_log_func)
    openlog(id, LOG_NDELAY | LOG_PID, facility)
    eal_log_set_default


rte_eal_vfio_setup
    rte_vfio_enable("vfio")
        for (i = 0; i < VFIO_MAX_CONTAINERS; i++) -> 64
            for (j = 0; j < VFIO_MAX_GROUPS; j++) -> 64
        vfio_available = rte_eal_check_module(modname) -> vfio：避免在模块未加载时启用，当内核支持 vfio 功能时未加载 vfio 模块时，例程仍尝试打开容器以获取文件描述。 此操作不安全，当然会收到错误消息： EAL: Detected 40 lcore(s) EAL: unsupported IOMMU type! EAL: VFIO 支持无法初始化 EAL: 设置内存...这可能会让用户感到困惑，这个补丁使用户更合理、更流畅
        /sys/module/vfio
        default_vfio_cfg->vfio_container_fd = rte_vfio_get_container_fd()
            open(VFIO_CONTAINER_PATH, O_RDWR) -> open /dev/vfio/vfio
        or vfio_get_default_container_fd
        static const struct vfio_iommu_type iommu_types[]




rte_eal_memzone_init
    rte_fbarray_init(&mcfg->memzones, "memzone",
    fully_validate
    rte_mem_page_size
    eal_get_virtual_area
    eal_get_fbarray_path
    eal_file_open
    resize_and_map
    map_addr = rte_mem_map(addr, len, RTE_PROT_READ | RTE_PROT_WRITE, RTE_MAP_SHARED | RTE_MAP_FORCE_ADDRESS, fd, 0);
    TAILQ_INSERT_TAIL(&mem_area_tailq, ma, next)


rte_eal_memory_init
    rte_eal_memseg_init
        memseg_primary_init -> eal_dynmem_memseg_lists_init
            eal_memseg_list_init
                eal_memseg_list_init_named

            eal_memseg_list_alloc
    eal_memalloc_init
        (rte_memseg_list_walk(fd_list_create_walk, NULL)
            alloc_list

    rte_eal_hugepage_init
        eal_legacy_hugepage_init or
        eal_dynmem_hugepage_init
            eal_dynmem_calc_num_pages_per_socket
    or rte_eal_hugepage_attach
    rte_eal_memdevice_init


rte_eal_malloc_heap_init
    malloc_add_seg


RTE_LCORE_FOREACH_WORKER(i)
    pipe(lcore_config[i].pipe_main2worker
    eal_worker_thread_create
        if (pthread_create(&lcore_config[lcore_id].thread_id, attrp, eal_thread_loop, (void *)(uintptr_t)lcore_id) == 0)
            eal_thread_wait_command
                n = read(m2w, &c, 1);
            eal_thread_ack_command
                n = write(w2m, &c, 1) <- eal_thread_wake_worker
    pthread_setaffinity_np
    rte_eal_mp_remote_launch(sync_func, NULL, SKIP_MAIN)
        rte_eal_remote_launch(f, arg, lcore_id)
            __atomic_store_n(&lcore_config[worker_id].f, f, __ATOMIC_RELEASE)
            eal_thread_wake_worker
    rte_eal_mp_wait_lcore


rte_service_init
    rte_services = rte_calloc("rte_services",


rte_bus_probe
    TAILQ_FOREACH(bus, &rte_bus_list, next) <- rte_bus_register <- RTE_REGISTER_BUS
        bus->probe()
    vbus->probe()
        auxiliary_probe(void)
        rte_dpaa_bus_probe
        rte_fslmc_probe
        ifpga_probe
        pci_probe(void)

vfio_mp_sync_setup
    rte_mp_action_register
        name: eal_vfio_mp_sync
        entry = malloc(sizeof(struct action_entry));
        find_action_entry_by_name
        TAILQ_INSERT_TAIL(&action_entry_list, entry, next)


rte_service_start_with_defaults

eal_clean_runtime_dir





EAL: Multi-process socket /var/run/dpdk/rte/mp_socket



struct rte_pci_bus rte_pci_bus = {
	.bus = {
		.scan = rte_pci_scan,
		.probe = pci_probe,
		.cleanup = pci_cleanup,
		.find_device = pci_find_device,
		.plug = pci_plug,
		.unplug = pci_unplug,
		.parse = pci_parse,
		.devargs_parse = rte_pci_devargs_parse,
		.dma_map = pci_dma_map,
		.dma_unmap = pci_dma_unmap,
		.get_iommu_class = rte_pci_get_iommu_class,
		.dev_iterate = rte_pci_dev_iterate,
		.hot_unplug_handler = pci_hot_unplug_handler,
		.sigbus_handler = pci_sigbus_handler,
	},
	.device_list = TAILQ_HEAD_INITIALIZER(rte_pci_bus.device_list),
	.driver_list = TAILQ_HEAD_INITIALIZER(rte_pci_bus.driver_list),
};


drivers/common/mlx5/mlx5_common_pci.c


dpdk init module, 
drivers/net/mlx5/mlx5.c
RTE_INIT(rte_mlx5_pmd_init)
    mlx5_common_init
        mlx5_glue_constructor
            mlx5_glue->fork_init() -> ibv_fork_init
        mlx5_common_driver_init -> common/mlx5：添加总线无关层，为了支持辅助总线，引入通用设备驱动程序和回调，应该取代mlx5通用PCI总线驱动程序。 Mlx5 类驱动程序，即 eth、vDPA、regex 和 compress 通常使用单个 Verbs 设备上下文来探测设备。 如果设备是 PCI 总线设备，则 Verbs 设备来自 PCI 地址；如果设备是辅助总线设备，则来自 Auxiliary sysfs。 目前仅支持 PCI 总线。 通用设备驱动程序是 mlx5 类驱动程序和总线之间的中间层，为类驱动程序解析和抽象总线信息到 Verbs 设备。 PCI总线驱动程序和辅助总线驱动程序都可以利用公共驱动程序层将总线操作转换为mlx5类驱动程序。 mlx5 eth、vDPA、正则表达式和压缩 PMD 仍在使用旧版 mlx5 通用 PCI 总线驱动程序，一旦所有 PMD 驱动程序迁移到新的通用驱动程序，该驱动程序将被删除
            mlx5_common_pci_init
                pci_ids_table_update -> 所有 mlx5 PMD 构造函数都以相同的优先级运行。 所以任何一个PMD，包括这个，都可以先注册PCI表。 如果任何其他 PMD 已注册 PCI ID 表，则无需注册空的默认表
                    pci_id_table_size_get
                    pci_id_insert(updated_table, &i, driver_id_table)
                    mlx5_pci_id_table = updated_table
                rte_pci_register(&mlx5_common_pci_driver)
                    TAILQ_INSERT_TAIL(&rte_pci_bus.driver_list, driver, next)
            mlx5_common_auxiliary_init
                rte_auxiliary_register(&mlx5_auxiliary_driver)
    mlx5_set_ptype_table
    mlx5_set_cksum_table
    mlx5_set_swp_types_table
    mlx5_class_driver_register(&mlx5_net_driver)


static struct rte_auxiliary_driver mlx5_auxiliary_driver = {
	.driver = {
		   .name = MLX5_AUXILIARY_DRIVER_NAME,
	},
	.match = mlx5_common_auxiliary_match,
	.probe = mlx5_common_auxiliary_probe,
	.remove = mlx5_common_auxiliary_remove,
	.dma_map = mlx5_common_auxiliary_dma_map,
	.dma_unmap = mlx5_common_auxiliary_dma_unmap,
};

static struct mlx5_class_driver mlx5_net_driver = {
	.drv_class = MLX5_CLASS_ETH,
	.name = RTE_STR(MLX5_ETH_DRIVER_NAME),
	.id_table = mlx5_pci_id_map,
	.probe = mlx5_os_net_probe,
	.remove = mlx5_net_remove,
	.probe_again = 1,
	.intr_lsc = 1,
	.intr_rmv = 1,
};



__rte_cache_aligned
const struct mlx5_glue *mlx5_glue = &(const struct mlx5_glue) {
	.version = MLX5_GLUE_VERSION,
	.fork_init = mlx5_glue_fork_init,
	.alloc_pd = mlx5_glue_alloc_pd,
	.dealloc_pd = mlx5_glue_dealloc_pd,
	.import_pd = mlx5_glue_import_pd,
	.unimport_pd = mlx5_glue_unimport_pd,
	.get_device_list = mlx5_glue_get_device_list,
	.free_device_list = mlx5_glue_free_device_list,
	.open_device = mlx5_glue_open_device,
	.import_device = mlx5_glue_import_device,
	.close_device = mlx5_glue_close_device,
	.query_device = mlx5_glue_query_device,
	.query_device_ex = mlx5_glue_query_device_ex,
	.get_device_name = mlx5_glue_get_device_name,
	.query_rt_values_ex = mlx5_glue_query_rt_values_ex,
	.query_port = mlx5_glue_query_port,
	.create_comp_channel = mlx5_glue_create_comp_channel,
	.destroy_comp_channel = mlx5_glue_destroy_comp_channel,
	.create_cq = mlx5_glue_create_cq,
	.destroy_cq = mlx5_glue_destroy_cq,
	.get_cq_event = mlx5_glue_get_cq_event,
	.ack_cq_events = mlx5_glue_ack_cq_events,
	.create_rwq_ind_table = mlx5_glue_create_rwq_ind_table,
	.destroy_rwq_ind_table = mlx5_glue_destroy_rwq_ind_table,
	.create_wq = mlx5_glue_create_wq,
	.destroy_wq = mlx5_glue_destroy_wq,
	.modify_wq = mlx5_glue_modify_wq,
	.create_flow = mlx5_glue_create_flow,
	.destroy_flow = mlx5_glue_destroy_flow,
	.destroy_flow_action = mlx5_glue_destroy_flow_action,
	.create_qp = mlx5_glue_create_qp,
	.create_qp_ex = mlx5_glue_create_qp_ex,
	.destroy_qp = mlx5_glue_destroy_qp,
	.modify_qp = mlx5_glue_modify_qp,
	.reg_mr = mlx5_glue_reg_mr,
	.reg_mr_iova = mlx5_glue_reg_mr_iova,
	.alloc_null_mr = mlx5_glue_alloc_null_mr,
	.dereg_mr = mlx5_glue_dereg_mr,
	.create_counter_set = mlx5_glue_create_counter_set,
	.destroy_counter_set = mlx5_glue_destroy_counter_set,
	.describe_counter_set = mlx5_glue_describe_counter_set,
	.query_counter_set = mlx5_glue_query_counter_set,
	.create_counters = mlx5_glue_create_counters,
	.destroy_counters = mlx5_glue_destroy_counters,
	.attach_counters = mlx5_glue_attach_counters,
	.query_counters = mlx5_glue_query_counters,
	.ack_async_event = mlx5_glue_ack_async_event,
	.get_async_event = mlx5_glue_get_async_event,
	.port_state_str = mlx5_glue_port_state_str,
	.cq_ex_to_cq = mlx5_glue_cq_ex_to_cq,
	.dr_create_flow_action_dest_flow_tbl =
		mlx5_glue_dr_create_flow_action_dest_flow_tbl,
	.dr_create_flow_action_dest_port =
		mlx5_glue_dr_create_flow_action_dest_port,
	.dr_create_flow_action_drop =
		mlx5_glue_dr_create_flow_action_drop,
	.dr_create_flow_action_push_vlan =
		mlx5_glue_dr_create_flow_action_push_vlan,
	.dr_create_flow_action_pop_vlan =
		mlx5_glue_dr_create_flow_action_pop_vlan,
	.dr_create_flow_tbl = mlx5_glue_dr_create_flow_tbl,
	.dr_destroy_flow_tbl = mlx5_glue_dr_destroy_flow_tbl,
	.dr_create_domain = mlx5_glue_dr_create_domain,
	.dr_destroy_domain = mlx5_glue_dr_destroy_domain,
	.dr_sync_domain = mlx5_glue_dr_sync_domain,
	.dv_create_cq = mlx5_glue_dv_create_cq,
	.dv_create_wq = mlx5_glue_dv_create_wq,
	.dv_query_device = mlx5_glue_dv_query_device,
	.dv_set_context_attr = mlx5_glue_dv_set_context_attr,
	.dv_init_obj = mlx5_glue_dv_init_obj,
	.dv_create_qp = mlx5_glue_dv_create_qp,
	.dv_create_flow_matcher = mlx5_glue_dv_create_flow_matcher,
	.dv_create_flow_matcher_root = __mlx5_glue_dv_create_flow_matcher,
	.dv_create_flow = mlx5_glue_dv_create_flow,
	.dv_create_flow_root = __mlx5_glue_dv_create_flow,
	.dv_create_flow_action_counter =
		mlx5_glue_dv_create_flow_action_counter,
	.dv_create_flow_action_dest_ibv_qp =
		mlx5_glue_dv_create_flow_action_dest_ibv_qp,
	.dv_create_flow_action_dest_devx_tir =
		mlx5_glue_dv_create_flow_action_dest_devx_tir,
	.dv_create_flow_action_modify_header =
		mlx5_glue_dv_create_flow_action_modify_header,
	.dv_create_flow_action_modify_header_root =
		__mlx5_glue_dv_create_flow_action_modify_header,
	.dv_create_flow_action_packet_reformat =
		mlx5_glue_dv_create_flow_action_packet_reformat,
	.dv_create_flow_action_packet_reformat_root =
		__mlx5_glue_dv_create_flow_action_packet_reformat,
	.dv_create_flow_action_tag =  mlx5_glue_dv_create_flow_action_tag,
	.dv_create_flow_action_meter = mlx5_glue_dv_create_flow_action_meter,
	.dv_modify_flow_action_meter = mlx5_glue_dv_modify_flow_action_meter,
	.dv_create_flow_action_aso = mlx5_glue_dv_create_flow_action_aso,
	.dr_create_flow_action_default_miss =
		mlx5_glue_dr_create_flow_action_default_miss,
	.dv_destroy_flow = mlx5_glue_dv_destroy_flow,
	.dv_destroy_flow_matcher = mlx5_glue_dv_destroy_flow_matcher,
	.dv_destroy_flow_matcher_root = __mlx5_glue_dv_destroy_flow_matcher,
	.dv_open_device = mlx5_glue_dv_open_device,
	.devx_obj_create = mlx5_glue_devx_obj_create,
	.devx_obj_destroy = mlx5_glue_devx_obj_destroy,
	.devx_obj_query = mlx5_glue_devx_obj_query,
	.devx_obj_modify = mlx5_glue_devx_obj_modify,
	.devx_general_cmd = mlx5_glue_devx_general_cmd,
	.devx_create_cmd_comp = mlx5_glue_devx_create_cmd_comp,
	.devx_destroy_cmd_comp = mlx5_glue_devx_destroy_cmd_comp,
	.devx_obj_query_async = mlx5_glue_devx_obj_query_async,
	.devx_get_async_cmd_comp = mlx5_glue_devx_get_async_cmd_comp,
	.devx_umem_reg = mlx5_glue_devx_umem_reg,
	.devx_umem_dereg = mlx5_glue_devx_umem_dereg,
	.devx_qp_query = mlx5_glue_devx_qp_query,
	.devx_wq_query = mlx5_glue_devx_wq_query,
	.devx_port_query = mlx5_glue_devx_port_query,
	.dr_dump_domain = mlx5_glue_dr_dump_domain,
	.dr_dump_rule = mlx5_glue_dr_dump_single_rule,
	.dr_reclaim_domain_memory = mlx5_glue_dr_reclaim_domain_memory,
	.dr_create_flow_action_sampler =
		mlx5_glue_dr_create_flow_action_sampler,
	.dr_create_flow_action_dest_array =
		mlx5_glue_dr_action_create_dest_array,
	.dr_allow_duplicate_rules = mlx5_glue_dr_allow_duplicate_rules,
	.devx_query_eqn = mlx5_glue_devx_query_eqn,
	.devx_create_event_channel = mlx5_glue_devx_create_event_channel,
	.devx_destroy_event_channel = mlx5_glue_devx_destroy_event_channel,
	.devx_subscribe_devx_event = mlx5_glue_devx_subscribe_devx_event,
	.devx_subscribe_devx_event_fd = mlx5_glue_devx_subscribe_devx_event_fd,
	.devx_get_event = mlx5_glue_devx_get_event,
	.devx_alloc_uar = mlx5_glue_devx_alloc_uar,
	.devx_free_uar = mlx5_glue_devx_free_uar,
	.dv_alloc_var = mlx5_glue_dv_alloc_var,
	.dv_free_var = mlx5_glue_dv_free_var,
	.dv_alloc_pp = mlx5_glue_dv_alloc_pp,
	.dv_free_pp = mlx5_glue_dv_free_pp,
	.dr_create_flow_action_send_to_kernel =
		mlx5_glue_dr_create_flow_action_send_to_kernel,
};


mlx5_os_get_ibv_dev
mlx5_os_get_ibv_device


rte_telemetry_init
    telemetry_v2_init
        rte_telemetry_register_cmd("/"
            callbacks[i].fn = fn
        rte_telemetry_register_cmd("/info"
        v2_socket.sock = create_socket(v2_socket.path)
        pthread_create(&t_new, NULL, socket_listener, &v2_socket)
            int s_accepted = accept(s->sock, NULL, NULL)
            pthread_create(&th, NULL, s->fn,
    or telemetry_legacy_init



rte_log_register_type_and_pick_level


eal_mcfg_complete
    internal_conf->init_complete = 1;





verification/st/dpdk/st_dpdk.c -> main -> rx
rte_eal_init
sprintf(dut2dpi_addr, "/home/common/st_socket/%s/dut2dpi", argv[1]);
sprintf(dpi2dut_addr, "/home/common/st_socket/%s/dpi2dut", argv[1]);
rte_eth_dev_count_avail
rte_pktmbuf_pool_create("MBUF_POOL", NUM_MBUFS * nb_ports,
RTE_ETH_FOREACH_DEV
    port_init
        rte_eth_dev_info_get
        rte_eth_dev_configure
        rte_eth_dev_adjust_nb_rx_tx_desc
        rte_eth_rx_queue_setup
        rte_eth_dev_socket_id
        rte_eth_tx_queue_setup
        rte_eth_dev_socket_id
        rte_eth_dev_start
        rte_eth_macaddr_get
        rte_eth_promiscuous_enable
RTE_LCORE_FOREACH_WORKER
    rte_eal_remote_launch(lcore_dpdk2eda_rx, NULL, lcore_id)
        init_server
        RTE_ETH_FOREACH_DEV(port)
            rte_eth_rx_burst(port, 0,
            deal_dpdk2eda_msg -> deal_eda_dpdk_msg
                epoll_wait
                rqe_alloc_db
                deal_listenfd_epollin
                deal_clientfd_epollin
                edamsg2pkt
                    rte_pktmbuf_reset_headroom
                    rte_memcpy(rte_pktmbuf_mtod_offset(pkt, char *, 0),
                pkt2edamsg
                epoll_ctl
lcore_eda2dpdk_tx(mbuf_pool) -> tx
    RTE_ETH_FOREACH_DEV(port)
        init_server(&listenfd, &epollfd, dut2dpi_addr) -> 
    for (;;)
        RTE_ETH_FOREACH_DEV(port)
            deal_eda2dpdk_msg(listenfd, epollfd, bufs, mbuf_pool) -> deal_eda_dpdk_msg
                mbufs[trans_cnt] = rte_pktmbuf_alloc(mbuf_pool)
                edamsg2pkt
            rte_eth_tx_burst
rte_eal_mp_wait_lcore




struct rte_mbuf {
    ...
    void *buf_addr;
    ...
}



doca,
I used the following commands on the DPU to install dpdk:
wget https://fast.dpdk.org/rel/dpdk-22.11.2.tar.xz 1
tar xf dpdk-22.11.2.tar.xz
cd dpdk-stable-22.11.2
meson build
meson configure -Ddisable_drivers=regex/cn9k build
meson setup soc_build -Dplatform=bluefield
ninja -C build
ninja -C build install
pkg-config --modversion libdpdk

And then you can set the hugepages:
echo 1024 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages



vfio
usertools/dpdk-devbind.py



mlx5_os_net_probe(struct mlx5_common_device *cdev, struct mlx5_kvargs_ctrl *mkvlist)
    mlx5_pmd_socket_init -> 
        socket, fcntl, bind, listen -> #define MLX5_SOCKET_PATH "/var/tmp/dpdk_net_mlx5_%d"
        server_intr_handle = mlx5_os_interrupt_handler_create(RTE_INTR_INSTANCE_F_PRIVATE, false, server_socket, mlx5_pmd_socket_handle, NULL)
            tmp_intr_handle = rte_intr_instance_alloc(mode)
            rte_intr_fd_set
            rte_intr_type_set
            rte_intr_callback_register
                callback->cb_fn = cb -> mlx5_pmd_socket_handle
    mlx5_init_once
        mlx5_init_shared_data
        mlx5_mp_init_primary(MLX5_MP_NAME, mlx5_mp_os_primary_handle)
            rte_mp_action_register(name, primary_action)
                entry = malloc(sizeof(struct action_entry))
                TAILQ_INSERT_TAIL(&action_entry_list, entry, next)
        mlx5_mp_init_secondary(MLX5_MP_NAME, mlx5_mp_os_secondary_handle)
    mlx5_probe_again_args_validate
        mlx5_shared_dev_ctx_args_config(sh, mkvlist, config)
            config->cnt_svc.service_core = rte_get_main_lcore()
            mlx5_kvargs_process(mkvlist, params, mlx5_dev_args_check_handler, config)
            mlx5_devx_obj_ops_en
    mlx5_os_pci_probe
    or mlx5_os_auxiliary_probe
        mlx5_os_parse_eth_devargs
        mlx5_auxiliary_get_ifindex
        mlx5_dev_spawn
            rte_eth_dev_get_port_by_name
            mlx5_alloc_shared_dev_ctx
            mlx5_proc_priv_init
            eth_dev->rx_pkt_burst = mlx5_select_rx_function(eth_dev)
            eth_dev->tx_pkt_burst = mlx5_select_tx_function(eth_dev)
            priv->representor_id = mlx5_representor_id_encode(switch_info, eth_da->type)
            rte_eth_switch_domain_alloc
            mlx5_port_args_config
            rte_eth_dev_allocate
            mlx5_get_mtu
            eth_dev->rx_pkt_burst = rte_eth_pkt_burst_dummy;
        rte_eth_dev_probing_finish




mlx5_mp_os_primary_handle
    mlx5_mp_os_handle_port_agnostic
    rte_eth_dev_is_valid_port
    case MLX5_MP_REQ_QUEUE_TX_START
        mlx5_tx_queue_start_primary
            txq_obj_modify -> mlx5_txq_devx_modify
                mlx5_devx_cmd_modify_sq
                    MLX5_SET(modify_sq_in, in, opcode, MLX5_CMD_OP_MODIFY_SQ)
                    ret = mlx5_glue->devx_obj_modify(sq->obj, in, sizeof(in), out, sizeof(out)) -> mlx5_glue_devx_obj_modify
                        return devx_cmd(GET_OBJ_CTX(obj), in, inlen, out, outlen) -> return execute_ioctl(((struct devx_context *)ctx)->cmd_fd, cmd) -> https://github.com/Mellanox/devx/blob/master/src/devx.c



rte_eth_dev_tx_queue_start(uint16_t port_id, uint16_t tx_queue_id)
    eth_dev_validate_tx_queue
    rte_eth_dev_is_tx_hairpin_queue
    dev->dev_ops->tx_queue_start(dev, tx_queue_id) -> mlx5_tx_queue_start
        txq_obj_modify




REGISTER_TEST_COMMAND(latencystats_autotest, test_latencystats)
    test_latency_packet_forward



dpdk test plan: https://doc.dpdk.org/dts/test_plans/index.html

e810 rx timestamp: https://doc.dpdk.org/dts/test_plans/rx_timestamp_perf_test_plan.html
 <build_dir>/app/dpdk-testpmd -l 5,6 -n 8 --force-max-simd-bitwidth=64 \
 -- -i --portmask=0x3 --rxq=1 --txq=1 --txd=1024 --rxd=1024 --forward=mac \
 --nb-cores=1 --enable-rx-timestamp

Note:
  -force-max-simd-bitwidth: Set 64, the feature only support 64.
  -enable-rx-timestamp: enable rx-timestamp.


使用 E810 对标头分割转发的性能进行基准测试: https://doc.dpdk.org/dts/test_plans/ice_header_split_perf_test_plan.html
bind: ./usertools/dpdk-devbind.py -b vfio-pci 17:00.0 4b:00.0
<build_dir>/app/dpdk-testpmd -l 5,6 -n 8 --force-max-simd-bitwidth=64 \
 -- -i --portmask=0x3 --rxq=1 --txq=1 --txd=1024 --rxd=1024 --forward=rxonly \
 --nb-cores=1 --mbuf-size=2048,2048
port start all
start





fs_tx_queue_start


testpmd + pdump




./dpdk-vhost_blk -m 1024




rte_ctrl_thread_create
    pthread_create(thread, attr, ctrl_thread_init, (void *)params) <- qemu connect vhost.socket
        return start_routine(routine_arg) -> fdset_event_dispatch
            rcb(fd, dat, &remove1) -> vhost_user_server_new_connection
                fd = accept(fd, NULL, NULL)
                vhost_user_add_connection(fd, vsocket)
                    vid = vhost_new_device()
                    vhost_setup_virtio_net
                    vhost_attach_vdpa_device
                    ret = vsocket->notify_ops->new_connection(vid) -> new_connection -> vhost_session_install_rte_compat_hooks
                        rte_vhost_extern_callback_register(vid, &g_extern_vhost_ops, NULL)
                    ret = fdset_add(&vhost_user.fdset, fd, vhost_user_read_cb, NULL, conn) -> vhost_user_read_cb
                        vhost_user_msg_handler
                            "read message %s\n", msg_handler->descriptionread -> message VHOST_USER_GET_FEATURES
                            switch (request)
                            case VHOST_USER_SET_FEATURES:
                            case VHOST_USER_SET_PROTOCOL_FEATURES:
                            case VHOST_USER_SET_OWNER:
                            case VHOST_USER_SET_MEM_TABLE:
                            case VHOST_USER_SET_LOG_BASE:
                            case VHOST_USER_SET_LOG_FD:
                            case VHOST_USER_SET_VRING_NUM:
                            case VHOST_USER_SET_VRING_ADDR:
                            case VHOST_USER_SET_VRING_BASE:
                            case VHOST_USER_SET_VRING_KICK:
                            case VHOST_USER_SET_VRING_CALL:
                            case VHOST_USER_SET_VRING_ERR:
                            case VHOST_USER_SET_VRING_ENABLE:
                            case VHOST_USER_SEND_RARP:
                            case VHOST_USER_NET_SET_MTU:
                            case VHOST_USER_SET_SLAVE_REQ_FD:
                            msg_result = (*dev->extern_ops.pre_msg_handle)(dev->vid, &ctx)
                            msg_result = msg_handler->callback(&dev, &ctx, fd)
                                -> vhost_user_get_features
                                    rte_vhost_driver_get_features(dev->ifname, &features)
                                        vdpa_dev->ops->get_features(vdpa_dev, &vdpa_features)
                            case RTE_VHOST_MSG_RESULT_REPLY:
                                send_vhost_reply(dev, fd, &ctx)
                            msg_result = (*dev->extern_ops.post_msg_handle)(dev->vid, &ctx)
                            if (dev->notify_ops->new_device(dev->vid) -> config vdpa device -> vdpa new device
                    TAILQ_INSERT_TAIL(&vsocket->conn_list, conn, next)



struct rte_vhost_user_extern_ops g_extern_vhost_ops = {
	.pre_msg_handle = extern_vhost_pre_msg_handler,
        rte_vhost_get_ifname(vid, path, PATH_MAX)
        ctrlr = vhost_blk_ctrlr_find(path)
        switch ((int)msg->request)
	.post_msg_handle = extern_vhost_post_msg_handler,

};


vhost protocol seq:
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) new vhost user connection is 1319
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) new device, handle is 0
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_GET_FEATURES
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_GET_PROTOCOL_FEATURES
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_PROTOCOL_FEATURES
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) negotiated Vhost-user protocol features: 0x11ebf
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_GET_QUEUE_NUM
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_SLAVE_REQ_FD
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_OWNER
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_GET_FEATURES
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_VRING_CALL
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) vring call idx:0 file:1321
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_VRING_ERR
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_FEATURES
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) negotiated Virtio features: 0x140000000
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_GET_STATUS
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_STATUS
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) new device status(0x00000008):
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket)      -RESET: 0
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket)      -ACKNOWLEDGE: 0
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket)      -DRIVER: 0
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket)      -FEATURES_OK: 1
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket)      -DRIVER_OK: 0
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket)      -DEVICE_NEED_RESET: 0
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket)      -FAILED: 0
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_INFLIGHT_FD
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) set_inflight_fd mmap_size: 2112
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) set_inflight_fd mmap_offset: 0
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) set_inflight_fd num_queues: 1
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) set_inflight_fd queue_size: 128
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) set_inflight_fd fd: 1322
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) set_inflight_fd pervq_inflight_size: 2112
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_VRING_CALL
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) vring call idx:0 file:1323
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_FEATURES
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) negotiated Virtio features: 0x140000000
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_GET_STATUS
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) read message VHOST_USER_SET_VRING_CALL
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) vring call idx:0 file:1321
VHOST_CONFIG: (/root/project/net/dpdk/build/examples/vhost.socket) vhost peer closed


usage(char* progname)
    --latencystats



testpmd -> main
    signal_handler
    rte_log_register
    rte_eal_init
    Selected IOVA mode 'VA'
    init_port
    register_eth_event_callback
    rte_eth_dev_callback_register(RTE_ETH_ALL, event, eth_event_callback,
        eth_event_callback

    rte_pdump_init
        rte_memzone_reserve(MZ_RTE_PDUMP_STATS, sizeof(*pdump_stats),
        rte_mp_action_register(PDUMP_MP, pdump_server)
    set_def_fwd_config
        set_default_fwd_lcores_config
        set_def_peer_eth_addrs
        set_default_fwd_ports_config
            rte_eth_dev_socket_id
    launch_args_parse
    init_config
        init_config_port_offloads
        mbuf_pool_create(mbuf_data_size[j],
        init_port_config


examples/vhost_blk/vhost_blk.c -> main
    rte_eal_init
    g_vhost_ctrlr = vhost_blk_ctrlr_construct(CTRLR_NAME) -> "vhost.socket" -> /root/project/net/dpdk/build/examples/vhost.socket
        rte_vhost_driver_register(dev_pathname, 0)
        create_unix_socket(vsocket)
        rte_vhost_driver_set_features(dev_pathname, VHOST_BLK_FEATURES)
        ctrlr->bdev = vhost_blk_bdev_construct("malloc0", "vhost_blk_malloc0", 4096, 32768, 0)
        rte_vhost_driver_callback_register(dev_pathname, &vhost_blk_device_ops)
            vsocket->notify_ops = ops
    rte_vhost_driver_start(dev_pathname)
        fdset_pipe_init(&vhost_user.fdset)
        rte_ctrl_thread_create(&fdset_tid, "vhost-events", NULL, fdset_event_dispatch, &vhost_user.fdset)
        vhost_user_start_server(vsocket) -> bind -> listen
            fdset_add(&vhost_user.fdset, fd, vhost_user_server_new_connection, NULL, vsocket)
        or vhost_user_start_client(vsocket)



struct rte_vhost_device_ops vhost_blk_device_ops = {
	.new_device =  new_device,
	.destroy_device = destroy_device,
	.new_connection = new_connection,
};



vhost_kernel_get_features
    vhost_kernel_ioctl(data->vhostfds[0], VHOST_GET_FEATURES, features)



struct virtio_user_backend_ops virtio_ops_vdpa = {
	.setup = vhost_vdpa_setup,
	.destroy = vhost_vdpa_destroy,
	.get_backend_features = vhost_vdpa_get_backend_features,
	.set_owner = vhost_vdpa_set_owner,
	.get_features = vhost_vdpa_get_features,
        vhost_vdpa_ioctl(data->vhostfd, VHOST_GET_FEATURES, features) -> kernel -> .unlocked_ioctl	= vhost_vdpa_unlocked_ioctl
	.set_features = vhost_vdpa_set_features,
	.set_memory_table = vhost_vdpa_set_memory_table,
        vhost_vdpa_iotlb_batch_begin
        vhost_vdpa_dma_unmap
        rte_memseg_contig_walk_thread_unsafe(vhost_vdpa_map_contig, dev)
            vhost_vdpa_dma_map(dev, ms->addr, ms->iova, len)
        rte_memseg_walk_thread_unsafe(vhost_vdpa_map, dev)
        vhost_vdpa_iotlb_batch_end
	.set_vring_num = vhost_vdpa_set_vring_num,
	.set_vring_base = vhost_vdpa_set_vring_base,
	.get_vring_base = vhost_vdpa_get_vring_base,
	.set_vring_call = vhost_vdpa_set_vring_call,
	.set_vring_kick = vhost_vdpa_set_vring_kick,
	.set_vring_addr = vhost_vdpa_set_vring_addr,
	.get_status = vhost_vdpa_get_status,
	.set_status = vhost_vdpa_set_status,
	.get_config = vhost_vdpa_get_config,
	.set_config = vhost_vdpa_set_config,
	.enable_qp = vhost_vdpa_enable_queue_pair,
	.dma_map = vhost_vdpa_dma_map_batch,
	.dma_unmap = vhost_vdpa_dma_unmap_batch,
	.update_link_state = vhost_vdpa_update_link_state,
	.get_intr_fd = vhost_vdpa_get_intr_fd,
};



struct virtio_user_backend_ops virtio_ops_user = {
    .setup = vhost_user_setup,
    .destroy = vhost_user_destroy,
    .get_backend_features = vhost_user_get_backend_features,
    .set_owner = vhost_user_set_owner,
    .get_features = vhost_user_get_features,
    .set_features = vhost_user_set_features,
    .set_memory_table = vhost_user_set_memory_table,
        .request = VHOST_USER_SET_MEM_TABLE
        rte_memseg_walk_thread_unsafe(update_memory_region, &wa) -> 此函数不执行任何锁定，并且只能在与内存相关的回调函数中安全调用
            mr->guest_phys_addr = start_addr;
            mr->userspace_addr = start_addr;
            mr->memory_size = ms->len;
            mr->mmap_offset = offset;
        vhost_user_write(data->vhostfd, &msg, fds, fd_num)
    .set_vring_num = vhost_user_set_vring_num,
    .set_vring_base = vhost_user_set_vring_base, -> virtio device sends us the available ring last used index
        vq->last_avail_idx = val & 0x7fff
    .get_vring_base = vhost_user_get_vring_base, -> when virtio is stopped, qemu will send us the GET_VRING_BASE message
        vhost_destroy_device_notify(dev)
            vdpa_dev->ops->dev_close(dev->vid)
        vhost_user_iotlb_flush_all(vq) -> vhost：在 vring 停止时清理 IOTLB 缓存，当 VM 中的 virtio 驱动程序发生更改时，会留下旧的 IOVA 缓存条目。如果所有这些旧条目的 iova 地址都小于新的 iova 条目，则 vhost 代码将需要迭代所有缓存以查找新条目。如果新转换只需要一个新的 iova 条目，这种情况将永远持续下去。在 virtio-net 到 testpmd 的 vfio-pci 驱动程序转换中已经观察到这种情况，如果大页面地址高于网络缓冲区，则性能会从超过 10Mpps 降低到不到 0.07Mpps。由于所有新缓冲区都包含在这个新的巨型页面中，因此 vhost 最坏情况下需要为每个转换扫描 IOTLB_CACHE_SIZE - 1
            vhost_user_iotlb_cache_remove_all
                for
                    TAILQ_REMOVE(&vq->iotlb_list, node, next)
                    vhost_user_iotlb_pool_put(vq, node)
                        SLIST_INSERT_HEAD(&vq->iotlb_free_list, node, next_free)
            vhost_user_iotlb_pending_remove_all
        vring_invalidate(dev, vq)
            vq->access_ok = false;
            vq->desc = NULL;
            vq->avail = NULL;
            vq->used = NULL;
            vq->log_guest_addr = 0;
    .set_vring_call = vhost_user_set_vring_call,
        vq = dev->virtqueue[file.index]
        vq->callfd = file.fd
    .set_vring_kick = vhost_user_set_vring_kick,
        vq = dev->virtqueue[file.index]
        translate_ring_addresses(&dev, &vq)
        vq->kickfd = file.fd
        vhost_check_queue_inflights_packed
            resubmit = rte_zmalloc_socket("resubmit", sizeof(struct rte_vhost_resubmit_info), 0, vq->numa_node)
    .set_vring_addr = vhost_user_set_vring_addr, -> virtio 设备向我们发送 desc、used 和 avail 环地址。然后此函数将它们转换为我们的地址空间
        struct vhost_vring_addr *addr = &ctx->msg.payload.addr
        vq = dev->virtqueue[ctx->msg.payload.addr.index]
        memcpy(&vq->ring_addrs, addr, sizeof(*addr))
        vring_invalidate
        translate_ring_addresses(&dev, &vq)
            if (vq->ring_addrs.flags & (1 << VHOST_VRING_F_LOG))
                vq->log_guest_addr = log_addr_to_gpa(dev, vq)
            if (vq_is_packed(dev))
                vq->desc_packed = (struct vring_packed_desc *)(uintptr_t)ring_addr_to_vva(dev, vq, vq->ring_addrs.desc_user_addr, &len) -> 将环地址转换为 Vhost 虚拟地址。如果启用了 IOMMU，则环地址为客户机 IO 虚拟地址，否则为 QEMU 虚拟地址
                    if (dev->features & (1ULL << VIRTIO_F_IOMMU_PLATFORM))
                        vhost_iova_to_vva(dev, vq, ra, size, VHOST_ACCESS_RW) -> vhost：确保在转换 QVA 时映射所有范围，此补丁确保在将地址从主地址（例如 QEMU 主机地址）转换为进程 VA 时映射所有地址范围
                            rte_vhost_va_from_guest_pa(dev->mem, iova, len) -> Convert guest physical address to host virtual address
                            or __vhost_iova_to_vva(dev, vq, iova, len, perm)
                                vva = vhost_user_iotlb_cache_find(vq, iova, &tmp_size, perm)
                                    TAILQ_FOREACH(node, &vq->iotlb_list, next)
                                if (!vhost_user_iotlb_pending_miss(vq, iova, perm))
                                    vhost_user_iotlb_pending_insert
                                        node = vhost_user_iotlb_pool_get(vq)
                                            node = SLIST_FIRST(&vq->iotlb_free_list)
                                            SLIST_REMOVE_HEAD(&vq->iotlb_free_list, next_free)
                                        TAILQ_INSERT_TAIL(&vq->iotlb_pending_list, node, next)
                                    vhost_user_iotlb_miss
                                        .request.slave = VHOST_USER_SLAVE_IOTLB_MSG
                                        send_vhost_message(dev, dev->slave_req_fd, &ctx)
                                            send_fd_message(dev->ifname, sockfd, (char *)&ctx->msg, VHOST_USER_HDR_SIZE + ctx->msg.size, ctx->fds, ctx->fd_num)
                    qva_to_vva(dev, ra, size) ->  Converts QEMU virtual address to Vhost virtual address
                        for (i = 0; i < dev->mem->nregions; i++)
                numa_realloc(&dev, &vq) -> vhost：保留对 virtqueue 索引的引用，在 dev->virtqueue[] 数组中拥有对 vq 索引的反向引用，可以统一内部 API，只需传递 dev 和 vq。它还允许在日志消息中显示 vq 索引。删除不需要的 virtqueue 索引检查（例如在所有可用 virtqueue 上循环调用的静态帮助程序）。尽快移动 virtqueue 索引有效性检查
    .get_status = vhost_user_get_status,
    .set_status = vhost_user_set_status,
    .enable_qp = vhost_user_enable_queue_pair,
    .update_link_state = vhost_user_update_link_state,
    .server_disconnect = vhost_user_server_disconnect,
    .server_reconnect = vhost_user_server_reconnect,
    .get_intr_fd = vhost_user_get_intr_fd,
};



dpdk/drivers/net/virtio/virtio_user_ethdev.c
RTE_PMD_REGISTER_VDEV(net_virtio_user, virtio_user_driver);
static struct rte_vdev_driver virtio_user_driver = {
	.probe = virtio_user_pmd_probe,
	.remove = virtio_user_pmd_remove,
	.dma_map = virtio_user_pmd_dma_map,
	.dma_unmap = virtio_user_pmd_dma_unmap,
};
virtio_user_pmd_probe
    virtio_user_dev_setup
        switch (dev->backend_type)
        case VIRTIO_USER_BACKEND_VHOST_USER:
            dev->ops = &virtio_ops_user
        case VIRTIO_USER_BACKEND_VHOST_KERNEL
            dev->ops = &virtio_ops_kernel
        case VIRTIO_USER_BACKEND_VHOST_VDPA:
            dev->ops = &virtio_ops_vdpa
        dev->ops->setup(dev)
        virtio_user_dev_init_notify
        virtio_user_fill_intr_handle
    virtio_user_dev_init
        dev->ops->get_features(dev, &dev->device_features)


struct virtio_user_backend_ops virtio_ops_kernel = {
	.setup = vhost_kernel_setup,
	.destroy = vhost_kernel_destroy,
	.get_backend_features = vhost_kernel_get_backend_features,
	.set_owner = vhost_kernel_set_owner,
	.get_features = vhost_kernel_get_features,
	.set_features = vhost_kernel_set_features,
	.set_memory_table = vhost_kernel_set_memory_table,
	.set_vring_num = vhost_kernel_set_vring_num,
	.set_vring_base = vhost_kernel_set_vring_base,
	.get_vring_base = vhost_kernel_get_vring_base,
	.set_vring_call = vhost_kernel_set_vring_call,
	.set_vring_kick = vhost_kernel_set_vring_kick,
	.set_vring_addr = vhost_kernel_set_vring_addr,
	.get_status = vhost_kernel_get_status,
	.set_status = vhost_kernel_set_status,
	.enable_qp = vhost_kernel_enable_queue_pair,
	.update_link_state = vhost_kernel_update_link_state,
	.get_intr_fd = vhost_kernel_get_intr_fd,
};


vhost_kernel_set_memory_table
    vhost_kernel_ioctl(data->vhostfds[i], VHOST_SET_MEM_TABLE, vm)


virtio_user_set_status
    virtio_user_start_device
        dev->ops->set_memory_table(dev)


#define VHOST_MESSAGE_HANDLERS \
VHOST_MESSAGE_HANDLER(VHOST_USER_NONE, NULL, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_GET_FEATURES, vhost_user_get_features, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_FEATURES, vhost_user_set_features, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_OWNER, vhost_user_set_owner, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_RESET_OWNER, vhost_user_reset_owner, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_MEM_TABLE, vhost_user_set_mem_table, true) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_LOG_BASE, vhost_user_set_log_base, true) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_LOG_FD, vhost_user_set_log_fd, true) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_VRING_NUM, vhost_user_set_vring_num, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_VRING_ADDR, vhost_user_set_vring_addr, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_VRING_BASE, vhost_user_set_vring_base, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_GET_VRING_BASE, vhost_user_get_vring_base, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_VRING_KICK, vhost_user_set_vring_kick, true) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_VRING_CALL, vhost_user_set_vring_call, true) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_VRING_ERR, vhost_user_set_vring_err, true) \
VHOST_MESSAGE_HANDLER(VHOST_USER_GET_PROTOCOL_FEATURES, vhost_user_get_protocol_features, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_PROTOCOL_FEATURES, vhost_user_set_protocol_features, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_GET_QUEUE_NUM, vhost_user_get_queue_num, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_VRING_ENABLE, vhost_user_set_vring_enable, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SEND_RARP, vhost_user_send_rarp, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_NET_SET_MTU, vhost_user_net_set_mtu, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_SLAVE_REQ_FD, vhost_user_set_req_fd, true) \
VHOST_MESSAGE_HANDLER(VHOST_USER_IOTLB_MSG, vhost_user_iotlb_msg, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_GET_CONFIG, vhost_user_get_config, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_CONFIG, vhost_user_set_config, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_POSTCOPY_ADVISE, vhost_user_set_postcopy_advise, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_POSTCOPY_LISTEN, vhost_user_set_postcopy_listen, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_POSTCOPY_END, vhost_user_postcopy_end, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_GET_INFLIGHT_FD, vhost_user_get_inflight_fd, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_INFLIGHT_FD, vhost_user_set_inflight_fd, true) \
VHOST_MESSAGE_HANDLER(VHOST_USER_SET_STATUS, vhost_user_set_status, false) \
VHOST_MESSAGE_HANDLER(VHOST_USER_GET_STATUS, vhost_user_get_status, false)


vhost_user_set_mem_table(struct virtio_net **pdev, struct vhu_msg_context *ctx, int main_fd)
    vhost_memory_changed(memory, dev->mem)
    dev->notify_ops->vring_state_changed(dev->vid, i, 0) -> stop dma
        vring_conf_update(vid, eth_dev, vring)
        update_queuing_status(eth_dev, false)
        rte_eth_dev_callback_process(eth_dev, RTE_ETH_EVENT_QUEUE_STATE, NULL)
    vhost_user_iotlb_flush_all(dev->virtqueue[i])
    dev->guest_pages = rte_zmalloc_socket(NULL, dev->max_guest_pages *sizeof(struct guest_page), RTE_CACHE_LINE_SIZE, numa_node)
    dev->mem = rte_zmalloc_socket("vhost-mem-table", sizeof(struct rte_vhost_memory) + sizeof(struct rte_vhost_mem_region) * memory->nregions, 0, numa_node)
    for (i = 0; i < memory->nregions; i++)
        reg->guest_phys_addr = memory->regions[i].guest_phys_addr
        reg->guest_user_addr = memory->regions[i].userspace_addr;
        reg->size            = memory->regions[i].memory_size;
        reg->fd              = ctx->fds[i];
        mmap_offset = memory->regions[i].mmap_offset
        vhost_user_mmap_region(dev, reg, mmap_offset)
    async_dma_map(dev, true)
    vhost_user_postcopy_register(dev, main_fd, ctx)
    for (i = 0; i < dev->nr_vring; i++)
        vring_invalidate(dev, vq)
        translate_ring_addresses(&dev, &vq)
        dev->notify_ops->vring_state_changed(dev->vid, i, 1)



xilinx, librte_pmd_sfc_vdpa, sfc_efx, ef100 设备可以配置为网络设备或 vDPA 模式。添加“class=vdpa”参数有助于指定此设备将在 vDPA 模式下使用。如果未指定此参数，设备将由 net/sfc 驱动程序探测并用作网络设备, 该 PMD 使用 libefx（common/sfc_efx）代码来访问设备固件 -> AMD 现已收购 Solarflare，可提供 XtremeScale 系列网络接口控制器 -> commit: https://github.com/ssbandjl/dpdk/commit/5e7596ba7cb3b1f07a605edf6c816d355e84dc26
SFC: Solarflare Communications
RTE_INIT(sfc_efx_register_logtype)

RTE_PMD_REGISTER_PCI(net_sfc_vdpa, rte_sfc_vdpa)
sfc_vdpa_pci_probe
    logtype_main = sfc_vdpa_register_logtype(&pci_dev->addr, SFC_VDPA_LOGTYPE_MAIN_STR, RTE_LOG_NOTICE)
    sfc_vdpa_set_log_prefix(sva)
        snprintf(sva->log_prefix, sizeof(sva->log_prefix),"PMD: sfc_vdpa " PCI_PRI_FMT " : ",pci_dev->addr.domain, pci_dev->addr.bus, pci_dev->addr.devid, pci_dev->addr.function)
    sfc_vdpa_kvargs_parse(sva)
        sva->kvargs = rte_kvargs_parse(devargs->args, params)
    sfc_vdpa_adapter_lock_init(sva)
    sfc_vdpa_vfio_setup(sva)
        sva->vfio_container_fd = rte_vfio_container_create()
            vfio_cfgs[i].vfio_container_fd = rte_vfio_get_container_fd()
                vfio_container_fd = open(VFIO_CONTAINER_PATH, O_RDWR) -> /dev/vfio/vfio
        rte_vfio_get_group_num(rte_pci_get_sysfs_path(), dev_name, &sva->iommu_group_num)
            snprintf(linkname, sizeof(linkname), "%s/%s/iommu_group", sysfs_base, dev_addr)
        sva->vfio_group_fd = rte_vfio_container_group_bind(sva->vfio_container_fd, sva->iommu_group_num)
            vfio_cfg = get_vfio_cfg_by_container_fd(container_fd)
            vfio_get_group_fd(vfio_cfg, iommu_group_num)
                vfio_group_fd = vfio_open_group_fd(iommu_group_num) -> /dev/vfio/%u
                    rte_mp_request_sync(&mp_req, &mp_reply, &ts) -> vfio：使用通用多进程通道，以前，vfio 使用自己的私有通道供次进程从主进程获取容器 fd 和组 fd。此补丁更改为使用通用 mp 通道 -> 向对等进程发送请求并等待回复。此函数向对等进程发送请求消息，并将阻塞直到收到对等进程的回复消息。
        rte_pci_map_device(dev) -> 映射PCI设备BAR资源
        sva->vfio_dev_fd = rte_intr_dev_fd_get(dev->intr_handle)
    sfc_vdpa_hw_init
        sfc_efx_family(sva->pdev, &mem_ebr, &sva->family)
            static const efx_pci_ops_t ops = {
                .epo_config_readd = sfc_efx_pci_config_readd, -> rte_pci_read_config
                .epo_find_mem_bar = sfc_efx_find_mem_bar,
            };
            efx_family_probe_bar(pci_dev->id.vendor_id, pci_dev->id.device_id, &espcp, &ops, family, mem_ebrp)
                case EFX_PCI_DEVID_RIVERHEAD_VF
                    rhead_pci_nic_membar_lookup
                        efx_pci_find_next_xilinx_cap_table -> epo_config_readd
                        rhead_xilinx_cap_tbl_find_ef100_locator
                            rhead_nic_xilinx_cap_tbl_read_ef100_locator
                        epo_find_mem_bar -> sfc_efx_find_mem_bar
                efx_family(venid, devid, efp, &membar)
        sfc_vdpa_mem_bar_init(sva, &mem_ebr)
        efx_nic_create(sva->family, (efsys_identifier_t *)sva, &sva->mem_bar, mem_ebr.ebr_offset, &sva->nic_lock, &enp)
            case EFX_FAMILY_MEDFORD
                enp->en_enop = &__efx_nic_medford_ops
            case EFX_FAMILY_MEDFORD2
                enp->en_enop = &__efx_nic_medford2_ops
            case EFX_FAMILY_RIVERHEAD
                enp->en_enop = &__efx_nic_riverhead_ops
        sfc_vdpa_mcdi_init(sva)
            sfc_efx_mcdi_init(&sva->mcdi, logtype,sva->log_prefix, sva->nic, &sfc_vdpa_mcdi_ops, sva)
        sfc_vdpa_nic_probe(sva)
            efx_phy_probe
                epop = &__efx_phy_ef10_ops
        efx_nic_reset(enp)
        efx_virtio_init(enp)
            evop = &__efx_virtio_rhead_ops
        sfc_vdpa_estimate_resource_limits(sva)
        efx_filter_init(enp)
    sva->ops_data = sfc_vdpa_device_init(sva, SFC_VDPA_AS_VF)
        ops_data->vdpa_dev = rte_vdpa_register_device(&pci_dev->device, &sfc_vdpa_ops)
    TAILQ_INSERT_TAIL(&sfc_vdpa_adapter_list, sva, next)


static struct rte_vdpa_dev_ops sfc_vdpa_ops = {
	.get_queue_num = sfc_vdpa_get_queue_num,
	.get_features = sfc_vdpa_get_features,
	.get_protocol_features = sfc_vdpa_get_protocol_features,
	.dev_conf = sfc_vdpa_dev_config,
	.dev_close = sfc_vdpa_dev_close,
	.set_vring_state = sfc_vdpa_set_vring_state,
	.set_features = sfc_vdpa_set_features,
	.get_vfio_device_fd = sfc_vdpa_get_vfio_device_fd,
	.get_notify_area = sfc_vdpa_get_notify_area,
        *offset = reg.offset + (uint64_t)ops_data->vq_cxt[qid].doorbell
        doorbell = (uint8_t *)pci_dev->mem_resource[reg.index].addr + *offset
        rte_write16(qid, doorbell) -> VM 中的 virtio-net 驱动程序在 vDPA 有机会设置队列和通知区域之前发送队列通知，因此 HW 错过了这些门铃通知。由于发送重复门铃是安全的，因此从 vDPA 驱动程序发送另一个门铃作为解决此时间问题的解决方法
};


static const efx_virtio_ops_t	__efx_virtio_rhead_ops = {
	rhead_virtio_qstart,			/* evo_virtio_qstart */
	rhead_virtio_qstop,			/* evo_virtio_qstop */
	rhead_virtio_get_doorbell_offset,	/* evo_get_doorbell_offset */
	rhead_virtio_get_features,		/* evo_get_features */
	rhead_virtio_verify_features,		/* evo_verify_features */
};

static const efx_phy_ops_t	__efx_phy_ef10_ops = {
	ef10_phy_power,			/* epo_power */
	NULL,				/* epo_reset */
	ef10_phy_reconfigure,		/* epo_reconfigure */
	ef10_phy_verify,		/* epo_verify */
	ef10_phy_oui_get,		/* epo_oui_get */
	ef10_phy_link_state_get,	/* epo_link_state_get */
#if EFSYS_OPT_PHY_STATS
	ef10_phy_stats_update,		/* epo_stats_update */
#endif	/* EFSYS_OPT_PHY_STATS */
#if EFSYS_OPT_BIST
	ef10_bist_enable_offline,	/* epo_bist_enable_offline */
	ef10_bist_start,		/* epo_bist_start */
	ef10_bist_poll,			/* epo_bist_poll */
	ef10_bist_stop,			/* epo_bist_stop */
#endif	/* EFSYS_OPT_BIST */
};



static const struct sfc_efx_mcdi_ops sfc_vdpa_mcdi_ops = {
	.dma_alloc	= sfc_vdpa_mcdi_dma_alloc,
        mz = rte_memzone_reserve_aligned(mz_name, mcdi_buff_size, numa_node, RTE_MEMZONE_IOVA_CONTIG, PAGE_SIZE)
        rte_vfio_container_dma_map(sva->vfio_container_fd, (uint64_t)mz->addr, mcdi_iova, mcdi_buff_size)
	.dma_free	= sfc_vdpa_mcdi_dma_free,
	.sched_restart  = sfc_vdpa_mcdi_sched_restart,
	.mgmt_evq_poll  = sfc_vdpa_mcdi_mgmt_evq_poll,
};

static const efx_nic_ops_t	__efx_nic_medford_ops = {
	ef10_nic_probe,			/* eno_probe */
	medford_board_cfg,		/* eno_board_cfg */
	ef10_nic_set_drv_limits,	/* eno_set_drv_limits */
	ef10_nic_reset,			/* eno_reset */
	ef10_nic_init,			/* eno_init */
	ef10_nic_get_vi_pool,		/* eno_get_vi_pool */
	ef10_nic_get_bar_region,	/* eno_get_bar_region */
	ef10_nic_hw_unavailable,	/* eno_hw_unavailable */
	ef10_nic_set_hw_unavailable,	/* eno_set_hw_unavailable */
#if EFSYS_OPT_DIAG
	ef10_nic_register_test,		/* eno_register_test */
#endif	/* EFSYS_OPT_DIAG */
	ef10_nic_fini,			/* eno_fini */
	ef10_nic_unprobe,		/* eno_unprobe */
};


shm, rte_eth_dev_attach_secondary
rte_eth_dev_pci_allocate




cmdline_parse_inst_t cmd_create_vdpa_port
    cmd_create_vdpa_port_parsed
        dev = rte_vdpa_find_device_by_name(res->bdf)
        start_vdpa(&vports[devcnt]
